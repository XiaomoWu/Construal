{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true"
   },
   "source": [
    "# Kickstarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datatable as dt\n",
    "import mmcv\n",
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "from datatable import f\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "from tqdm.auto import tqdm\n",
    "from utilpy import sv, ld\n",
    "\n",
    "dt.init_styles()\n",
    "\n",
    "wdir = '/home/yu/OneDrive/Construal'\n",
    "model_dir = f'{wdir}/pretrained_models/mmdetection'\n",
    "data_dir = f'{wdir}/data'\n",
    "\n",
    "os.chdir(wdir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to model config and checkpoint file\n",
    "config_file = f'{model_dir}/configs/lvis/mask_rcnn_x101_64x4d_fpn_sample1e-3_mstrain_1x_lvis_v1.py'\n",
    "# config_file = f'{model_dir}/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\n",
    "\n",
    "checkpoint_file = f'{model_dir}/checkpoints/mask_rcnn_x101_64x4d_fpn_sample1e-3_mstrain_1x_lvis_v1-43d9edfe.pth'\n",
    "# checkpoint_file = f'{model_dir}/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac87c39e",
   "metadata": {},
   "source": [
    "## unit test\n",
    "\n",
    "> plot results and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pid of \"product design\"\n",
    "# pjson = ld('pjson', folder=data_dir)\n",
    "# pids = pjson[(f.category=='Product Design'),f.pid].to_list()[0]\n",
    "\n",
    "# print(f'{len(pids)=}')\n",
    "\n",
    "# init models\n",
    "device = 'cuda:0'\n",
    "model = init_detector(config_file, checkpoint_file, device=device)\n",
    "\n",
    "# get pids\n",
    "img_dir = f'{data_dir}/sharing/object-detect-example-v3'\n",
    "imgs = os.listdir(img_dir)\n",
    "\n",
    "for img_path in ['8.png']:\n",
    "    out_img_path = f'{img_dir}/out-{img_path}'\n",
    "    img_path = f'{img_dir}/{img_path}'\n",
    "\n",
    "    # only process png\n",
    "    if (not img_path.endswith('.png')) or (not os.path.exists(img_path)):\n",
    "        continue\n",
    "\n",
    "    # detect\n",
    "    res = inference_detector(model, img_path)\n",
    "\n",
    "    # print visualization\n",
    "    show_result_pyplot(model, img_path, res, palette=None, score_thr=0.5)\n",
    "\n",
    "    # save results to disk\n",
    "    model.show_result(img_path, res, \n",
    "                      score_thr=0.5,\n",
    "                      out_file=f'{out_img_path}', show=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"pjson.feather\" (167.5 MB) loaded (<1s) (2023-05-14 7:20 PM)\n",
      "len(pids)=3759\n"
     ]
    }
   ],
   "source": [
    "# get pid of \"product design\"\n",
    "pjson = ld('pjson', folder=data_dir)\n",
    "pids = pjson[(f.category=='Product Design') | (f.category=='Accessories'),f.pid].to_list()[0]\n",
    "\n",
    "print(f'{len(pids)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start Detecting!\n",
    "def obj_detect(pid, model):\n",
    "    pdir = f'{data_dir}/kickstarter-image/{pid}'\n",
    "    output = {}\n",
    "    if not os.path.exists(pdir):\n",
    "        return\n",
    "\n",
    "    for i, file in enumerate(os.listdir(pdir)):\n",
    "        if file.endswith('.jpg'):\n",
    "            img = f'{pdir}/{file}'\n",
    "            res = inference_detector(model, img)\n",
    "            \n",
    "            # get cat_idx and cat_n\n",
    "            # res[0]: box\n",
    "            # res[1]: segment\n",
    "            box_res = {}\n",
    "            for cat_idx, cat in enumerate(res[0]):\n",
    "                if len(cat)>0:\n",
    "                    box_res[cat_idx] = {'n':len(cat),\n",
    "                                        'prob':cat[:,-1].tolist()}\n",
    "            \n",
    "            output[file] = box_res\n",
    "\n",
    "    # save results\n",
    "    save_dir = f'{pdir}/object results'\n",
    "    save_path = f'{save_dir}/mrcnn_lvis.pt'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_dir)\n",
    "    torch.save(output, save_path)\n",
    "    \n",
    "# device = f'cuda:0'\n",
    "device = 'cpu'\n",
    "model = init_detector(config_file, checkpoint_file, device=device)\n",
    "\n",
    "for pid in tqdm(pids[99:100]):\n",
    "    obj_detect(pid, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retreving results for sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"pjson.feather\" (167.5 MB) loaded (<1s) (2021-10-18 4:03 PM)\n",
      "len(pids)=3759\n"
     ]
    }
   ],
   "source": [
    "# get pid of \"product design\"\n",
    "ld('pjson', path=data_dir)\n",
    "pids = pjson[(f.category=='Product Design') | (f.category=='Accessories'),f.pid].to_list()[0]\n",
    "print(f'{len(pids)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3759/3759 [00:00<00:00, 8545.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "#  copy obj-detect results from the original folder to the sharing folder\n",
    "# ---------------------\n",
    "\n",
    "# create a new folder in the sharing folder\n",
    "target = f'{data_dir}/sharing/object-detect-results'\n",
    "\n",
    "if os.path.exists(target):\n",
    "    shutil.rmtree(target)\n",
    "os.mkdir(target)\n",
    "\n",
    "def save_sharing(pid):\n",
    "    pdir = f'{data_dir}/kickstarter-image/{pid}/object results'\n",
    "    if not os.path.exists(pdir):\n",
    "        return\n",
    "\n",
    "    target_dir = f'{target}/{pid}'\n",
    "    if not os.path.exists(target_dir):\n",
    "        shutil.copytree(pdir, target_dir)\n",
    "\n",
    "for pid in tqdm(pids):\n",
    "    save_sharing(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"df_objdet\" saved as \"df_objdet.feather\" (82.1 MB) (1s) (2021-10-18 4:18 PM)\n"
     ]
    }
   ],
   "source": [
    "# collect results into a single dataset \"df_objdet\"\n",
    "wdir = '/home/yu/OneDrive/Construal'\n",
    "os.chdir(wdir)\n",
    "\n",
    "import torch\n",
    "\n",
    "root_dir = '/home/yu/OneDrive/Construal/data/sharing/object-detect-results'\n",
    "\n",
    "detect_res = {}\n",
    "for i, pid in enumerate(os.listdir(root_dir)):\n",
    "    res = torch.load(f'{root_dir}/{pid}/mrcnn_lvis.pt')\n",
    "    detect_res[pid] = res\n",
    "    \n",
    "\n",
    "detect_df = []\n",
    "for pid, res in detect_res.items():\n",
    "    for jpg, labels in res.items():\n",
    "        for label_id, label_counts in labels.items():\n",
    "            for inst_id, prob in enumerate(label_counts['prob']):\n",
    "                detect_df.append((pid, jpg, label_id, inst_id, prob))\n",
    "detect_df = dt.Frame(detect_df, names=['pid', 'jpg', 'label_id', 'inst_id', 'prob'])\n",
    "\n",
    "sv('df_objdet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"df_objdet.feather\" (82.1 MB) loaded (0.69 secs) (2021-10-18 4:18 PM)\n",
      "\"lvis_dist.feather\" (80.4 KB) loaded (0 secs) (2021-10-18 4:18 PM)\n",
      "N unique pids: 3750 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 2 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>label_id</th><th scope=col>label_name</th><th scope=col>pid</th><th scope=col>jpg</th><th scope=col>inst_id</th><th scope=col>prob</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>11</td><td>antenna</td><td>563540633</td><td>profile_full.jpg</td><td>0</td><td>0.11811149</td></tr>\n",
       "\t<tr><td>11</td><td>antenna</td><td>563540633</td><td>profile_full.jpg</td><td>1</td><td>0.02381403</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 2 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " label\\_id & label\\_name & pid & jpg & inst\\_id & prob\\\\\n",
       " <int> & <chr> & <chr> & <chr> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 11 & antenna & 563540633 & profile\\_full.jpg & 0 & 0.11811149\\\\\n",
       "\t 11 & antenna & 563540633 & profile\\_full.jpg & 1 & 0.02381403\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 2 × 6\n",
       "\n",
       "| label_id &lt;int&gt; | label_name &lt;chr&gt; | pid &lt;chr&gt; | jpg &lt;chr&gt; | inst_id &lt;int&gt; | prob &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 11 | antenna | 563540633 | profile_full.jpg | 0 | 0.11811149 |\n",
       "| 11 | antenna | 563540633 | profile_full.jpg | 1 | 0.02381403 |\n",
       "\n"
      ],
      "text/plain": [
       "  label_id label_name pid       jpg              inst_id prob      \n",
       "1 11       antenna    563540633 profile_full.jpg 0       0.11811149\n",
       "2 11       antenna    563540633 profile_full.jpg 1       0.02381403"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"df_objdet\" saved as \"df_objdet.feather\" (112.2 MB) (0.64 secs, 2021-10-18 16:18:19)\n"
     ]
    }
   ],
   "source": [
    "# (required) add label_name to df_objdet (R)\n",
    "wdir = '/home/yu/OneDrive/Construal'\n",
    "setwd(wdir)\n",
    "\n",
    "ld(detect_df)\n",
    "ld(lvis_dist)\n",
    "\n",
    "detect_df = lvis_dist[, .(label_id=id, label_name=name)\n",
    "    ][detect_df, on=.(label_id)]\n",
    "\n",
    "npid = detect_df[, uniqueN(pid)]\n",
    "cat('N unique pids:', npid, '\\n')\n",
    "\n",
    "detect_df[1:2]\n",
    "\n",
    "sv(detect_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kickstarter (faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import concurrent\n",
    "import datatable as dt\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "from deepface import DeepFace\n",
    "from datatable import f\n",
    "from tqdm.auto import tqdm\n",
    "from retinaface import RetinaFace\n",
    "\n",
    "dt.init_styles()\n",
    "\n",
    "wdir = '/home/yu/OneDrive/Construal'\n",
    "model_dir = f'{wdir}/pretrained_models/mmdetection'\n",
    "data_dir = f'{wdir}/data'\n",
    "\n",
    "os.chdir(wdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pid of \"product design\"\n",
    "ld('pjson', path=data_dir)\n",
    "pids = pjson[(f.category=='Product Design') | (f.category=='Accessories'),f.pid].to_list()[0]\n",
    "\n",
    "print(f'{len(pids)=}')\n",
    "\n",
    "# Start Detecting!\n",
    "def face_detect(pid):\n",
    "    img = f'{data_dir}/kickstarter-image/{pid}/profile_full.jpg'\n",
    "    if not os.path.exists(img):\n",
    "        return\n",
    "\n",
    "    faces = RetinaFace.extract_faces(img)\n",
    "    n_faces = len(faces)\n",
    "    n_happy_faces = 0\n",
    "\n",
    "    if n_faces > 0:\n",
    "        for face in faces:\n",
    "            obj = DeepFace.analyze(face, detector_backend='skip', actions=['emotion'])\n",
    "            if obj['dominant_emotion'] == 'happy':\n",
    "                n_happy_faces += 1\n",
    "    \n",
    "    return pid, n_faces, n_happy_faces\n",
    "            \n",
    "            \n",
    "# out_faces = []\n",
    "# for pid in tqdm(pids[:10]):\n",
    "#     out_faces.append(face_detect(pid))\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    out_faces = list(executor.map(face_detect, pids))\n",
    "\n",
    "out_faces = [f for f in out_faces if f is not None]  # remove None\n",
    "out_faces = dt.Frame(out_faces, names=['pid', 'n_faces', 'n_happy_faces'])\n",
    "\n",
    "sv('out_faces')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0c33113",
   "metadata": {},
   "source": [
    "# Fiver\n",
    "\n",
    "Compatible with mmdetect>=3.0, no longer work with mmdetect2.x!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e713b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pyarrow.feather import write_feather, read_feather\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "wdir = Path('/home/yu/OneDrive/Construal')\n",
    "data_dir = Path('/home/yu/chaoyang/research-resources/fiver-raw-from-amrita/Image Folder')\n",
    "\n",
    "model_dir = f'{wdir}/pretrained_models/mmdetection'\n",
    "os.chdir(wdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bed641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "\n",
    "config_file = 'pretrained_models/lvis/mask-rcnn_x101-64x4d_fpn_sample1e-3_ms-1x_lvis-v1.py'\n",
    "checkpoint_file = 'pretrained_models/lvis/mask_rcnn_x101_64x4d_fpn_sample1e-3_mstrain_1x_lvis_v1-43d9edfe.pth'\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')  # or device='cuda:0'\n",
    "inference_detector(model, 'pretrained_models/test/demo.jpg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c96d1b5c",
   "metadata": {},
   "source": [
    "### config Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eedae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: pretrained_models/lvis/mask_rcnn_x101_64x4d_fpn_sample1e-3_mstrain_1x_lvis_v1-43d9edfe.pth\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to model config and checkpoint file\n",
    "config_file = 'pretrained_models/lvis/mask-rcnn_x101-64x4d_fpn_sample1e-3_ms-1x_lvis-v1.py'\n",
    "\n",
    "checkpoint_file = 'pretrained_models/lvis/mask_rcnn_x101_64x4d_fpn_sample1e-3_mstrain_1x_lvis_v1-43d9edfe.pth'\n",
    "\n",
    "device = 'cuda:0'\n",
    "model = init_detector(config_file, checkpoint_file, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1926dfe8",
   "metadata": {},
   "source": [
    "### run detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89701783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 665/4268 [04:32<21:14,  2.83it/s]Exception ignored in: <function _TemporaryFileCloser.__del__ at 0x7f7d57e35d80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/tempfile.py\", line 589, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/lib/python3.10/tempfile.py\", line 585, in close\n",
      "    unlink(self.name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpshgcf0zy/tmpf9njhp2_.py'\n",
      "Exception ignored in: <function _TemporaryFileCloser.__del__ at 0x7f7d57e35d80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/tempfile.py\", line 589, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/lib/python3.10/tempfile.py\", line 585, in close\n",
      "    unlink(self.name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpdxbiigu2/tmpwsj0jf8f.py'\n",
      "Exception ignored in: <function _TemporaryFileCloser.__del__ at 0x7f7d57e35d80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/tempfile.py\", line 589, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/lib/python3.10/tempfile.py\", line 585, in close\n",
      "    unlink(self.name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmph4q1ug2m/tmpu9fu1j3i.py'\n",
      "Exception ignored in: <function _TemporaryFileCloser.__del__ at 0x7f7d57e35d80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/tempfile.py\", line 589, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/lib/python3.10/tempfile.py\", line 585, in close\n",
      "    unlink(self.name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpjiqjx5bj/tmpe7umszy7.py'\n",
      "100%|██████████| 4268/4268 [29:38<00:00,  2.40it/s] \n"
     ]
    }
   ],
   "source": [
    "# function to detect objects\n",
    "def obj_detect(pid, model):\n",
    "    # pdir: project folder\n",
    "    pdir = data_dir/pid\n",
    "\n",
    "    if not pdir.exists():\n",
    "        return\n",
    "\n",
    "    for i, img_name in enumerate(os.listdir(pdir)):\n",
    "        if img_name.endswith('_main.jpg'):\n",
    "            img = f'{pdir}/{img_name}'\n",
    "            try:\n",
    "                res = inference_detector(model, img)\n",
    "            except:\n",
    "                return\n",
    "            \n",
    "            # collect cat_idx and prob\n",
    "            output = {}  # {file: {cat_idx: {n: , prob: }}}\n",
    "\n",
    "            cat_idxes = res.pred_instances.to_dict()['labels'].tolist()\n",
    "            probs = res.pred_instances.to_dict()['scores'].tolist()\n",
    "\n",
    "            for cat_idx, prob in zip(cat_idxes, probs):\n",
    "                if cat_idx not in output:\n",
    "                    output[cat_idx] = {'n': 1, 'prob': [prob]}\n",
    "                else:\n",
    "                    output[cat_idx]['n'] += 1\n",
    "                    output[cat_idx]['prob'].append(prob)\n",
    "\n",
    "    # create folder to save results\n",
    "    save_dir = wdir/'data/fiver-object-detect-results/'\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # save results\n",
    "    save_path = save_dir/f'{pid}_objects.pt'\n",
    "    if not save_path.exists():\n",
    "        torch.save(output, save_path)\n",
    "    \n",
    "# get pids\n",
    "pids = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(data_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('_main.jpg'):\n",
    "            pids.append(filename.split('_')[0])    \n",
    "\n",
    "# Start Detecting!\n",
    "for pid in tqdm(pids):\n",
    "    obj_detect(pid, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05032df5",
   "metadata": {},
   "source": [
    "### merge results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6c80ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect results into a dict\n",
    "res_dir = wdir/'data/fiver/object-detect-results'\n",
    "\n",
    "detect_res = {}\n",
    "for i, path in enumerate(os.listdir(res_dir)):\n",
    "    pid = path.split('_')[0]\n",
    "    res = torch.load(res_dir/path)\n",
    "    detect_res[pid] = res\n",
    "    \n",
    "\n",
    "# convert to dataframe\n",
    "detect_df = []\n",
    "for pid, res in detect_res.items():\n",
    "    for label_id, label_counts in res.items():\n",
    "        for inst_id, prob in enumerate(label_counts['prob']):\n",
    "            detect_df.append((pid, label_id, inst_id, prob))\n",
    "detect_df = pd.DataFrame(detect_df, columns=['pid', 'label_id', 'inst_id', 'prob'])\n",
    "\n",
    "# add \"label_name\"\n",
    "label_name = read_feather('data/lvis_dist.feather')[['id', 'name']]\n",
    "detect_df = detect_df.merge(label_name, left_on='label_id', right_on='id') \\\n",
    "    .drop(columns=['id']) \\\n",
    "    .rename({'name': 'label_name'}, axis=1)\n",
    "\n",
    "write_feather(detect_df, 'data/fiver/object-detect-res.feather')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "py39-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "04438afc90196b610ae9d8cae348c2d42203a24c961452fd32ef34edb45ea985"
   }
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "09caf020b66ce6dea8af4427bbd3bfec4c65fb4eccd0b5cc8d66aca214f16741"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
