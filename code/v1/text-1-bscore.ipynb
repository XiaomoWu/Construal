{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb54c15c",
   "metadata": {},
   "source": [
    "# Text Concreteness (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d444985",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yu's data science toolbox loaded! \n"
     ]
    }
   ],
   "source": [
    "suppressMessages(library(utilr))\n",
    "\n",
    "WORK_DIR = '/home/yu/OneDrive/Construal'\n",
    "setwd(WORK_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45392a11",
   "metadata": {},
   "source": [
    "## Create `dfm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d34306",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy is already initialized\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"pjson.feather\" (167.5 MB) loaded (0.32 secs) (2022-05-19 3:53 AM)\n"
     ]
    }
   ],
   "source": [
    "library(spacyr)\n",
    "library(quanteda)\n",
    "\n",
    "spacy_initialize(model='en_core_web_sm')\n",
    "\n",
    "pjson = ld('pjson', ldtype='feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6970e28e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# create corpus for \"project description\" and \"title\"\n",
    "corpus_desc = pjson[, .(pid, project_desc)] %>%\n",
    "    corpus(docid_field='pid', text_field='project_desc')\n",
    "corpus_title = pjson[, .(pid, title)] %>%\n",
    "    corpus(docid_field='pid', text_field='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49e151a6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"tokens_as_df_title\" saved as \"tokens_as_df_title.feather\" (6 MB) (0.04 secs, 2022-01-12 14:55:38)\n"
     ]
    }
   ],
   "source": [
    "# tokenize with spacy\n",
    "# the results is a data.frame\n",
    "# 1) keep both \"raw\" and \"lemma\" tokens \n",
    "# 2) tokens are case-sensitive\n",
    "\n",
    "tokens_as_df_desc = corpus_desc %>%\n",
    "    spacy_parse(pos=F, entity=F)\n",
    "tokens_as_df_title = corpus_title %>%\n",
    "    spacy_parse(pos=F, entity=F)\n",
    "\n",
    "sv(tokens_as_df_desc, svtype='rds')\n",
    "sv(tokens_as_df_title, svtype='rds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f01f0e1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_as_df_desc (141.2 MB) already loaded, will NOT load again! (0 secs) (2022-01-12 4:19 PM)\n",
      "tokens_as_df_title (2.2 MB) already loaded, will NOT load again! (0 secs) (2022-01-12 4:19 PM)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tokens consisting of 1 document.\n",
       "1000064918 :\n",
       "[1] \"\\n\"    \"the\"   \"Beard\" \"\\n\"   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"tokens_as_qeda_desc\" saved as \"tokens_as_qeda_desc.rds\" (48.2 MB) (10.18 secs, 2022-01-12 16:20:13)\n",
      "\"tokens_as_qeda_title\" saved as \"tokens_as_qeda_title.rds\" (1.5 MB) (0.28 secs, 2022-01-12 16:20:13)\n"
     ]
    }
   ],
   "source": [
    "# convert `tokens_as_df` to quanteda `tokens` object\n",
    "# 1) we use the lemmatized tokens, because the lookup table is also lemmatized \n",
    "# 2) tokens are case-sensitive\n",
    "\n",
    "ld(tokens_as_df_desc, ldtype='rds')\n",
    "ld(tokens_as_df_title, ldtype='rds')\n",
    "\n",
    "tokens_as_qeda_desc = tokens_as_df_desc %>%\n",
    "    as.tokens(use_lemma=T)\n",
    "tokens_as_qeda_title = tokens_as_df_title %>%\n",
    "    as.tokens(use_lemma=T)\n",
    "\n",
    "tokens_as_qeda_title[1]\n",
    "\n",
    "sv(tokens_as_qeda_desc)\n",
    "sv(tokens_as_qeda_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d628e2c3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>pid</th><th scope=col>ntoken_title</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1000064918</td><td>4</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 2\n",
       "\\begin{tabular}{ll}\n",
       " pid & ntoken\\_title\\\\\n",
       " <chr> & <int>\\\\\n",
       "\\hline\n",
       "\t 1000064918 & 4\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 2\n",
       "\n",
       "| pid &lt;chr&gt; | ntoken_title &lt;int&gt; |\n",
       "|---|---|\n",
       "| 1000064918 | 4 |\n",
       "\n"
      ],
      "text/plain": [
       "  pid        ntoken_title\n",
       "1 1000064918 4           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ntoken_corpus_title\" saved as \"ntoken_corpus_title.feather\" (562.4 KB) (0 secs, 2022-01-12 17:17:55)\n",
      "\"ntoken_corpus_desc\" saved as \"ntoken_corpus_desc.feather\" (607.9 KB) (0 secs, 2022-01-12 17:17:55)\n"
     ]
    }
   ],
   "source": [
    "# get the number of tokens of each doc\n",
    "ntoken_corpus_desc = ntoken(tokens_as_qeda_desc)\n",
    "ntoken_corpus_desc = data.table(pid=names(ntoken_corpus_desc), ntoken=ntoken_corpus_desc)\n",
    "\n",
    "ntoken_corpus_title = ntoken(tokens_as_qeda_title)\n",
    "ntoken_corpus_title = data.table(pid=names(ntoken_corpus_title), ntoken_title=ntoken_corpus_title)\n",
    "\n",
    "ntoken_corpus_title[1]\n",
    "sv(ntoken_corpus_title)\n",
    "sv(ntoken_corpus_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3f78d06",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"tokens_as_qeda_title.rds\" (1.5 MB) loaded (0.08 secs) (2022-01-12 4:20 PM)\n",
      "\"tokens_as_qeda_desc.rds\" (48.2 MB) loaded (0.97 secs) (2022-01-12 4:20 PM)\n",
      "\"cs_dfm_desc\" saved as \"cs_dfm_desc.rds\" (119.1 MB) (20.52 secs, 2022-01-12 16:21:52)\n",
      "\"cs_dfm_first200_desc\" saved as \"cs_dfm_first200_desc.rds\" (43.9 MB) (7.69 secs, 2022-01-12 16:22:00)\n",
      "\"cs_dfm_title\" saved as \"cs_dfm_title.rds\" (3.1 MB) (0.51 secs, 2022-01-12 16:22:00)\n"
     ]
    }
   ],
   "source": [
    "# Convert tokens to dfm\n",
    "ld(tokens_as_qeda_title, force=T)\n",
    "ld(tokens_as_qeda_desc, force=T)\n",
    "\n",
    "tokens_to_dfm <- function(tokens_as_qeda, startpos=1, endpos=-1) {\n",
    "    # select tokens\n",
    "    tokens = tokens_select(tokens_as_qeda, startpos=startpos, endpos=endpos)\n",
    "    \n",
    "    # create ngram\n",
    "    tokens_ngram = tokens %>%\n",
    "        tokens_ngrams(n=1:2, concatenator = \" \")\n",
    "    \n",
    "    # create dfm\n",
    "    cs_dfm = tokens_ngram %>% dfm(tolower=T, stem=F)\n",
    "}\n",
    "\n",
    "cs_dfm_desc = tokens_to_dfm(tokens_as_qeda_desc)\n",
    "cs_dfm_first200_desc = tokens_to_dfm(tokens_as_qeda_desc, endpos=200)\n",
    "cs_dfm_title = tokens_to_dfm(tokens_as_qeda_title)\n",
    "\n",
    "sv(cs_dfm_desc)\n",
    "sv(cs_dfm_first200_desc)\n",
    "sv(cs_dfm_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0b4ac",
   "metadata": {},
   "source": [
    "## Compute B-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f661643",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as \"nltk_stopwords.pkl\" (17.0 B) (<1s) (2022-01-12 3:43 PM)\n"
     ]
    }
   ],
   "source": [
    "# get stopwords from nltk (Python code)\n",
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "from utilpy import sv, ld\n",
    "from nltk.corpus import stopwords\n",
    "nltk.data.path.append('/home/yu/LocalData/nltk-data')\n",
    "os.chdir('/home/yu/OneDrive/Construal')\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "df = pd.DataFrame({'word':list(stopwords)})\n",
    "sv('df', svname='nltk_stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1962cd99",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"nltk_stopwords.feather\" (2.5 KB) loaded (0.02 secs) (2022-01-13 1:04 PM)\n",
      "0.310356910447018% words are stopwords"
     ]
    }
   ],
   "source": [
    "# ------------ Create bscore dict ----------------\n",
    "suppressMessages(library(utilr))\n",
    "WORK_DIR = '/home/yu/OneDrive/Construal'\n",
    "setwd(WORK_DIR)\n",
    "\n",
    "# load stop word list\n",
    "ld(nltk_stopwords, force=T)\n",
    "nltk_stopwords = nltk_stopwords[,word]\n",
    "\n",
    "# read raw bscore\n",
    "bscore_dt = fread('/home/yu/OneDrive/Construal/data/concreteness score.csv')[, .(word=str_trim(Word), score=Conc.M)]\n",
    "\n",
    "# create TWO bscore, one has stopwords, one doesn't \n",
    "bscore = bscore_dt$score\n",
    "names(bscore) = bscore_dt$word\n",
    "\n",
    "bscore_nostopwords = bscore[!(names(bscore)%in%nltk_stopwords)]\n",
    "\n",
    "sprintf('%s%% words are stopwords', (1-length(bscore_nostopwords)/length(bscore))*100%>%round(2)) %>% cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2499ea10",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntoken_corpus_desc (607.9 KB) already loaded, will NOT load again! (0 secs) (2022-01-12 4:38 PM)\n",
      "ntoken_corpus_title (562.3 KB) already loaded, will NOT load again! (0 secs) (2022-01-12 4:38 PM)\n",
      "\"cs_dfm_desc.rds\" (119.1 MB) loaded (3.55 secs) (2022-01-12 4:38 PM)\n",
      "\"cs_dfm_first200_desc.rds\" (43.9 MB) loaded (1.4 secs) (2022-01-12 4:38 PM)\n",
      "\"cs_dfm_title.rds\" (3.1 MB) loaded (0.15 secs) (2022-01-12 4:38 PM)\n",
      "\"bscore_nostopwords.rds\" (232.4 KB) loaded (0.03 secs) (2022-01-12 4:38 PM)\n"
     ]
    }
   ],
   "source": [
    "# ------------ Create bscore from dtm (for desc) ----------------\n",
    "\n",
    "ld(ntoken_corpus_desc)\n",
    "ld(ntoken_corpus_title)\n",
    "ld(cs_dfm_desc, force=T)\n",
    "ld(cs_dfm_first200_desc, force=T)\n",
    "ld(cs_dfm_title, force=T)\n",
    "ld(bscore_nostopwords, force=T)\n",
    "\n",
    "\n",
    "dfm_to_bscore <- function(cs_dfm, bscore_dict, type_name='') {\n",
    "    ntoken_name = str_c('ntoken_bscore', type_name)\n",
    "    ntoken_unique_name = str_c('ntoken_unique', type_name)\n",
    "    ntoken_bscore_unique_name = str_c('ntoken_bscore_unique', type_name)\n",
    "    bscore_name = str_c('bscore', type_name)\n",
    "    \n",
    "    output_name = c('pid', bscore_name)\n",
    "\n",
    "    ntoken_unique = ntype(cs_dfm)\n",
    "\n",
    "    dfm_bscore = dfm_match(cs_dfm, names(bscore_dict))\n",
    "    ntoken_bscore = ntoken(dfm_bscore)\n",
    "    ntoken_bscore_unique = ntype(dfm_bscore) \n",
    "    ntoken_bscore_dt = data.table(pid=names(ntoken_bscore))\n",
    "    ntoken_bscore_dt = ntoken_bscore_dt[, (ntoken_name) := ntoken_bscore\n",
    "        ][, (ntoken_unique_name) := ntoken_unique\n",
    "        ][, (ntoken_bscore_unique_name) := ntoken_bscore_unique]\n",
    "    \n",
    "    \n",
    "    dfm_bscore_weighted = dfm_weight(dfm_bscore, weights=bscore_dict)\n",
    "    dfm_bscore_weighted = convert(dfm_bscore_weighted, 'data.frame',\n",
    "                                  docid_field='pid'\n",
    "                                 ) %>% as.data.table()\n",
    "    \n",
    "    bscore_by_pid = dfm_bscore_weighted[, (bscore_name) := rowSums(.SD),\n",
    "                                        .SDcols=is.numeric\n",
    "        ][, ..output_name]\n",
    "    \n",
    "    bscore = bscore_by_pid[ntoken_bscore_dt, on=.(pid)]\n",
    "}\n",
    "\n",
    "bscore_bypid_desc = dfm_to_bscore(cs_dfm_desc, bscore)\n",
    "\n",
    "bscore_bypid_nostopwords_desc = dfm_to_bscore(\n",
    "    cs_dfm_desc, bscore_nostopwords, \n",
    "    type_name='_nostopwords')\n",
    "\n",
    "bscore_bypid_firstn_desc = dfm_to_bscore(\n",
    "    cs_dfm_first200_desc, bscore, \n",
    "    type_name='_first200')\n",
    "\n",
    "bscore_bypid_firstn_nostopwords_desc = dfm_to_bscore(\n",
    "    cs_dfm_first200_desc,\n",
    "    bscore_nostopwords,\n",
    "    type_name='_first200_nostopwords')\n",
    "\n",
    "bscore_bypid_title = dfm_to_bscore(\n",
    "    cs_dfm_title,\n",
    "    bscore)\n",
    "\n",
    "bscore_bypid_nostopwords_title = dfm_to_bscore(\n",
    "    cs_dfm_title,\n",
    "    bscore_nostopwords,\n",
    "    type_name='_nostopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e342d6d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"cs_dfm_title.rds\" (3.1 MB) loaded (0.13 secs) (2022-01-13 1:06 PM)\n",
      "\"bscore_nostopwords.rds\" (232.4 KB) loaded (0.02 secs) (2022-01-13 1:06 PM)\n",
      "ntoken_corpus_title (562.4 KB) already loaded, will NOT load again! (0 secs) (2022-01-13 1:06 PM)\n"
     ]
    }
   ],
   "source": [
    "# ------------ Create bscore from dtm (for title) ----------------\n",
    "ld(cs_dfm_title, force=T)\n",
    "ld(bscore_nostopwords, force=T)\n",
    "ld(ntoken_corpus_title)\n",
    "\n",
    "dfm_to_bscore <- function(cs_dfm, bscore_dict, type_name='') {\n",
    "    ntoken_name = str_c('ntoken_bscore', type_name)\n",
    "    ntoken_unique_name = str_c('ntoken_unique', type_name)\n",
    "    ntoken_bscore_unique_name = str_c('ntoken_bscore_unique', type_name)\n",
    "    bscore_name = str_c('bscore', type_name)\n",
    "    \n",
    "    output_name = c('pid', bscore_name)\n",
    "\n",
    "    ntoken_unique = ntype(cs_dfm)\n",
    "\n",
    "    dfm_bscore = dfm_match(cs_dfm, names(bscore_dict))\n",
    "    ntoken_bscore = ntoken(dfm_bscore)\n",
    "    ntoken_bscore_unique = ntype(dfm_bscore) \n",
    "    ntoken_bscore_dt = data.table(pid=names(ntoken_bscore))\n",
    "    ntoken_bscore_dt = ntoken_bscore_dt[, (ntoken_name) := ntoken_bscore\n",
    "        ][, (ntoken_unique_name) := ntoken_unique\n",
    "        ][, (ntoken_bscore_unique_name) := ntoken_bscore_unique]\n",
    "    \n",
    "    \n",
    "    dfm_bscore_weighted = dfm_weight(dfm_bscore, weights=bscore_dict)\n",
    "    dfm_bscore_weighted = convert(dfm_bscore_weighted, 'data.frame',\n",
    "                                  docid_field='pid'\n",
    "                                 ) %>% as.data.table()\n",
    "    \n",
    "    bscore_by_pid = dfm_bscore_weighted[, (bscore_name) := rowSums(.SD),\n",
    "                                        .SDcols=is.numeric\n",
    "        ][, ..output_name]\n",
    "    \n",
    "    bscore = bscore_by_pid[ntoken_bscore_dt, on=.(pid)]\n",
    "}\n",
    "\n",
    "bscore_bypid_title = dfm_to_bscore(\n",
    "    cs_dfm_title,\n",
    "    bscore)\n",
    "\n",
    "old_names = names(bscore_bypid_title)[-1]\n",
    "new_names = str_c(old_names, '_title')\n",
    "setnames(bscore_bypid_title, old_names, new_names)\n",
    "\n",
    "bscore_bypid_nostopwords_title = dfm_to_bscore(\n",
    "    cs_dfm_title,\n",
    "    bscore_nostopwords,\n",
    "    type_name='_nostopwords')\n",
    "    \n",
    "old_names = names(bscore_bypid_nostopwords_title)[-1]\n",
    "new_names = str_c(old_names, '_title')\n",
    "setnames(bscore_bypid_nostopwords_title, old_names, new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7abe786c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"bscore_bypid_final\" saved as \"bscore_bypid.feather\" (3.2 MB) (0.01 secs, 2022-01-12 17:22:48)\n"
     ]
    }
   ],
   "source": [
    "# --------------- combine all bscore datasets ----------------\n",
    "bscore_bypid_final = bscore_bypid_desc[bscore_bypid_nostopwords_desc, on=.(pid)\n",
    "    ][bscore_bypid_firstn_desc, on=.(pid)\n",
    "    ][bscore_bypid_firstn_nostopwords_desc, on=.(pid)\n",
    "    ][ntoken_corpus_desc, on=.(pid)\n",
    "    ][bscore_bypid_nostopwords_title, on=.(pid)\n",
    "    ][bscore_bypid_title, on=.(pid)\n",
    "    ][ntoken_corpus_title, on=.(pid)\n",
    "    ]\n",
    "\n",
    "\n",
    "sv(bscore_bypid_final, 'bscore_bypid')\n",
    "fwrite(bscore_bypid_final, './data/bscore_bypid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883edc5",
   "metadata": {},
   "source": [
    "# Word Freq (R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d233d",
   "metadata": {},
   "source": [
    "## Compute freq_dict\n",
    "\n",
    "### Compute the word frequency from the Google dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a6d64",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ld(tokens_as_df)\n",
    "ld(nltk_stopwords)\n",
    "\n",
    "google_freqdict_withstop = fread('data/freqdict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f132c9f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "google_freqdict = google_freqdict_withstop[\n",
    "      !(word %in% nltk_stopwords$word),\n",
    "    ][, .(word, freq_google_withoutstop=freq/max(freq))\n",
    "    ][google_freqdict_withstop[, .(word, freq_google_withstop=freq)], \n",
    "      on=.(word)\n",
    "    # ][, ':='(freq_google_withoutstop=nafill(freq_google_withoutstop, 'const', 0))\n",
    "    ][order(-freq_google_withstop)]\n",
    "\n",
    "google_freqdict[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99608306",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sv(google_freqdict)\n",
    "fwrite(google_freqdict, 'data/Sharing/google_freqdict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf996994",
   "metadata": {},
   "source": [
    "### Compute the word frequency from the Kickstarer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c8628",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "punct = c(',', '.', '-', '?', '!', '(', ')', '$', '/', ':', ' ', '\"', intToUtf8(160))\n",
    "\n",
    "kck_freqdict_withstopwords = tokens_as_df[, .(doc_id, word=tolower(token))\n",
    "    ][!(word %in% punct)\n",
    "    ][, .(n=.N), keyby=.(word)\n",
    "    ][, ':='(freq_kck_withstop=n/max(n))\n",
    "    ][order(-freq_kck_withstop), .(word, freq_kck_withstop)]\n",
    "\n",
    "kck_freqdict_withoutstopwords = tokens_as_df[, .(doc_id, word=tolower(token))\n",
    "    ][(!(word %in% punct)) & (!(word %in% nltk_stopwords$word))\n",
    "    ][, .(n=.N), keyby=.(word)\n",
    "    ][, ':='(freq_kck_withoutstop=n/max(n))\n",
    "    ][order(-freq_kck_withoutstop), .(word, freq_kck_withoutstop)]\n",
    "\n",
    "fwrite(kck_freqdict_withstopwords, 'data/Sharing/kck_freqdict_withstopwords.csv')\n",
    "fwrite(kck_freqdict_withoutstopwords, 'data/Sharing/kck_freqdict_withoutstopwords.csv')\n",
    "\n",
    "kck_freqdict = kck_freqdict_withoutstopwords[kck_freqdict_withstopwords, on=.(word)\n",
    "    # ][, ':='(freq_kck_withoutstop=nafill(freq_kck_withoutstop, 'const', 0))\n",
    "    ][order(-freq_kck_withstop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bc7f6a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ld(kck_freqdict)\n",
    "kck_freqdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179281f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fwrite(kck_freqdict, '../data/word_freq_kick.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a293006a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sv(kck_freqdict)\n",
    "fwrite(kck_freqdict, 'data/Sharing/kck_freqdict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7216f707",
   "metadata": {},
   "source": [
    "### Merge Kickstar_freq with Google_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e7155",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "freq_dict = google_freqdict[kck_freqdict, on=.(word)]\n",
    "freq_dict = freq_dict[order(-freq_google_withstop)\n",
    "    ][, ':='(\n",
    "      top_google_withoutstop=word %in% word[!is.na(freq_google_withoutstop)][1:5000],\n",
    "      top_google_withstop=word %in% word[!is.na(freq_google_withstop)][1:5000]\n",
    "      )\n",
    "    ][order(-freq_kck_withstop)\n",
    "    ][, ':='(\n",
    "      top_kck_withoutstop=word %in% word[!is.na(freq_kck_withoutstop)][1:5000],\n",
    "      top_kck_withstop=word %in% word[!is.na(freq_kck_withstop)][1:5000]\n",
    "      )]\n",
    "      \n",
    "sv(freq_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a5137b",
   "metadata": {},
   "source": [
    "## Compute score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a87e5e",
   "metadata": {},
   "source": [
    "Compute the \"frequency score\"\n",
    "\n",
    "- top 5000 words or all\n",
    "- with/without stopwords\n",
    "- based on kickstarter or LVIS\n",
    "\n",
    "So there're 2 * 2 * 2=8 versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db4110",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ld(freq_dict, force=T)\n",
    "freq_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f50715c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "punct = c(',', '.', '-', '?', '!', '(', ')', '$', '/', ':', ' ', '\"', intToUtf8(160))\n",
    "\n",
    "score = tokens_as_df[,.(doc_id, word=tolower(token))\n",
    "    ][!(word %in% punct)\n",
    "    ][freq_dict, \n",
    "      on=.(word), nomatch=NULL\n",
    "    ][, .(score_google_all_withstop=sum(freq_google_withstop, na.rm=T),\n",
    "          score_google_all_withoutstop=sum(freq_google_withoutstop, na.rm=T),\n",
    "          score_google_top5000_withstop=sum(freq_google_withstop[top_google_withstop], na.rm=T),\n",
    "          score_google_top5000_withoutstop=sum(freq_google_withoutstop[top_google_withstop], na.rm=T),\n",
    "          score_kck_all_withstop=sum(freq_kck_withstop, na.rm=T),\n",
    "          score_kck_all_withoutstop=sum(freq_kck_withoutstop, na.rm=T),\n",
    "          score_kck_top5000_withstop=sum(freq_kck_withstop[top_google_withstop], na.rm=T),\n",
    "          score_kck_top5000_withoutstop=sum(freq_kck_withoutstop[top_google_withstop], na.rm=T),\n",
    "          n_words_withstop=.N,\n",
    "          n_words_withoutstop=sum(!(word%in%(nltk_stopwords$word)))\n",
    "        ),\n",
    "      keyby=.(doc_id)]\n",
    "\n",
    "setnames(score, 'doc_id', 'pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb65e3db",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"score\" saved as \"score.feather\" (3.3 MB) (0.01 secs, 2021-10-16 22:54:03)\n"
     ]
    }
   ],
   "source": [
    "sv(score)\n",
    "fwrite(score, 'data/sharing/text_freq_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53344e47",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "score %>% names()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1580778a8a197288689bffd4ef3f72d3c9fd5cf473f27e207b33dc68ebf5c5f7"
  },
  "kernelspec": {
   "display_name": "R 4.1.2",
   "language": "R",
   "name": "ir410"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
