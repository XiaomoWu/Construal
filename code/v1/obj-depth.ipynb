{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Init"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import glob\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image as pil\n",
    "import torch\n",
    "\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# to import the pretrained model, first change working dir to its path,\n",
    "# then change back\n",
    "os.chdir('/home/yu/OneDrive/Construal/pretrained_MonoDepth2')\n",
    "\n",
    "import models, networks\n",
    "from layers import disp_to_depth\n",
    "\n",
    "os.chdir('/home/yu/OneDrive/Construal')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Resave image data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Create a new folder `data/Kickstarter Image/pid` which stores profile images for project with id `pid`. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_files(filename, search_path='data/Kickstarter Data'):\n",
    "    image_fullnames = []\n",
    "\n",
    "    # Walking top-down from the root\n",
    "    print('Searing for `profile_full.jpg`...')\n",
    "    for i, (root, dir, files) in enumerate(os.walk(search_path)):\n",
    "      # if i > 1e0:\n",
    "      #    break\n",
    "\n",
    "        if filename in files:\n",
    "            image_fullnames.append(os.path.join(root, filename).replace('\\\\', '/'))\n",
    "\n",
    "        assert len(set(image_fullnames)) == len(image_fullnames), 'Duplicate `profile_full.jpg` detected!'\n",
    "\n",
    "    # copy images to `data/Kictstarter Image`\n",
    "    print('Saving images...')\n",
    "    for name in tqdm(image_fullnames):\n",
    "        # get pid (project id)\n",
    "        pid = name.split('/')[-2]\n",
    "\n",
    "        # create one folder for each project, if not exist\n",
    "        pdir = f'data/KickStarter Image/{pid}'\n",
    "        if not os.path.exists(pdir):\n",
    "            os.mkdir(pdir)\n",
    "\n",
    "        copyfile(name, f'{pdir}/profile_full.jpg')\n",
    "\n",
    "    print('Done!')\n",
    "    return image_fullnames\n",
    "\n",
    "profile_images = find_files(\"profile_full.jpg\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Estismate Depth"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# list of image paths\n",
    "paths = glob.glob('data/Kickstarter Image/*/profile_full.jpg')\n",
    "\n",
    "# model path\n",
    "model_name = 'mono+stereo_640x192'\n",
    "model_path = f'pretrained_MonoDepth2/models/{model_name}'\n",
    "device = torch.device(\"cuda\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(\"-> Loading model from \", model_path)\n",
    "encoder_path = f'{model_path}/encoder.pth'\n",
    "depth_decoder_path = f'{model_path}/depth.pth'\n",
    "\n",
    "# LOADING PRETRAINED MODEL\n",
    "print(\"   Loading pretrained encoder\")\n",
    "encoder = networks.ResnetEncoder(18, False)\n",
    "loaded_dict_enc = torch.load(encoder_path, map_location=device)\n",
    "\n",
    "# extract the height and width of image that this model was trained with\n",
    "\n",
    "feed_height = loaded_dict_enc['height']\n",
    "feed_width = loaded_dict_enc['width']\n",
    "filtered_dict_enc = {k: v for k, v in loaded_dict_enc.items() if k in encoder.state_dict()}\n",
    "encoder.load_state_dict(filtered_dict_enc)\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "\n",
    "print(\"   Loading pretrained decoder\")\n",
    "depth_decoder = networks.DepthDecoder(\n",
    "    num_ch_enc=encoder.num_ch_enc, scales=range(4))\n",
    "\n",
    "loaded_dict = torch.load(depth_decoder_path, map_location=device)\n",
    "depth_decoder.load_state_dict(loaded_dict)\n",
    "\n",
    "depth_decoder.to(device)\n",
    "depth_decoder.eval();"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-> Loading model from  pretrained_MonoDepth2/models/mono+stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# FINDING INPUT IMAGES\n",
    "print(\"-> Predicting on {:d} test images\".format(len(paths)))\n",
    "\n",
    "# PREDICTING ON EACH IMAGE IN TURN\n",
    "with torch.no_grad():\n",
    "    for idx, image_path in enumerate(tqdm(paths)):\n",
    "        image_path = image_path.replace('\\\\','/')\n",
    "\n",
    "        # don't try to predict disparity for a disparity image!\n",
    "        if image_path.endswith(\"_disp.jpg\"):\n",
    "            continue\n",
    "\n",
    "        # if the img is already processed, skip\n",
    "        image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        pfolder = os.path.dirname(image_path)\n",
    "        name_dest_npy = f'{pfolder}/{image_name}_md2.npy'\n",
    "        name_dest_im = f'{pfolder}/{image_name}_md2.jpg'\n",
    "\n",
    "        if os.path.exists(name_dest_im) and os.path.exists(name_dest_npy):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Load image and preprocess\n",
    "            input_image = pil.open(image_path).convert('RGB')\n",
    "            original_width, original_height = input_image.size\n",
    "            input_image = input_image.resize((feed_width, feed_height), pil.LANCZOS)\n",
    "            input_image = transforms.ToTensor()(input_image).unsqueeze(0)\n",
    "\n",
    "            # PREDICTION\n",
    "            input_image = input_image.to(device)\n",
    "            features = encoder(input_image)\n",
    "            outputs = depth_decoder(features)\n",
    "\n",
    "            disp = outputs[(\"disp\", 0)]\n",
    "            disp_resized = torch.nn.functional.interpolate(\n",
    "                disp, (original_height, original_width), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "            # Saving numpy file\n",
    "            scaled_disp, _ = disp_to_depth(disp, 0.1, 100)\n",
    "            np.save(name_dest_npy, scaled_disp.cpu().numpy())\n",
    "\n",
    "            # Saving colormapped depth image\n",
    "            disp_resized_np = disp_resized.squeeze().cpu().numpy()\n",
    "            vmax = np.percentile(disp_resized_np, 95)\n",
    "            normalizer = mpl.colors.Normalize(vmin=disp_resized_np.min(), vmax=vmax)\n",
    "            mapper = cm.ScalarMappable(norm=normalizer, cmap='magma')\n",
    "            colormapped_im = (mapper.to_rgba(disp_resized_np)[:, :, :3] * 255).astype(np.uint8)\n",
    "            im = pil.fromarray(colormapped_im)\n",
    "            im.save(name_dest_im)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Exception @ {image_path}: {e}')\n",
    "            \n",
    "\n",
    "\n",
    "print('-> Done!')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.load('/home/yu/OneDrive/Construal/data/Kickstarter Image/1750261/profile_full_md2.npy')\n",
    "x[0,0,0,...]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "x.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 1, 192, 640)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}