{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared\n",
    "\n",
    "The code in this block will be used to compute uniqueness, readability, and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from pyarrow.feather import write_feather, read_feather\n",
    "from tqdm import tqdm\n",
    "\n",
    "wdir = Path('/home/yu/OneDrive/Construal/')\n",
    "os.chdir(wdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the V3D category list table (i.e., `cat_info`)\n",
    "- Category ID\n",
    "- Category name\n",
    "- Category description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category info of train\n",
    "# train and val are the same, so we only use train\n",
    "with open('pretrained-models/v3det/data/V3Det/annotations/v3det_2023_v1_train.json') as f:\n",
    "    cat_info = json.load(f)\n",
    "    cat_info = pd.DataFrame(cat_info['categories'])\n",
    "\n",
    "    write_feather(cat_info, 'data/v2/v3det/category_info.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect object detetion results on kickstarter projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:12<00:00, 301.43it/s] \n"
     ]
    }
   ],
   "source": [
    "# get file paths of object detection results\n",
    "p = wdir/'data/v2/v3det/on-kickstarter/per-image-results/'\n",
    "files = list(p.glob('*.pt'))\n",
    "\n",
    "# img root directory\n",
    "img_root = Path('/home/yu/chaoyang/research-resources/kickstart-raw-from-amrita/kickstarter-image')\n",
    "\n",
    "# loop over every image results\n",
    "obj_det_results = []\n",
    "for i, f in enumerate(tqdm(files)):\n",
    "    # load the results\n",
    "    df = torch.load(f)\n",
    "\n",
    "    # get size of each object\n",
    "    obj_size = [w*h for x, y, w, h in df['bboxes']]\n",
    "\n",
    "    # get the image path\n",
    "    img_path = img_root/f.stem/'profile_full.jpg'\n",
    "    if not img_path.exists():\n",
    "        continue\n",
    "\n",
    "    # get the image size\n",
    "    with Image.open(img_path) as img:\n",
    "        w, h = img.size\n",
    "        img_size = w * h\n",
    "\n",
    "    # get the ratio of each object\n",
    "    obj_size_ratio = [x/img_size for x in obj_size]\n",
    "    \n",
    "    # collect the results into a dataframe\n",
    "    df = pd.DataFrame(\n",
    "        {'pid': f.stem, 'label': df['labels'], 'score': df['scores'], \n",
    "         'size_ratio': obj_size_ratio})\n",
    "    obj_det_results.append(df)\n",
    "\n",
    "# covert to dataframe\n",
    "obj_det_results = pd.concat(obj_det_results, ignore_index=True)\n",
    "obj_det_results['label'] = obj_det_results['label'].astype(int) + 1\n",
    "write_feather(obj_det_results, 'data/v2/v3det/on-kickstarter/obj_det_results.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect object detetion results on v3d training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146965/146965 [01:28<00:00, 1652.67it/s]\n"
     ]
    }
   ],
   "source": [
    "#--- Collect per-image results into one dataframe ---#\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.utils import io\n",
    "from pyarrow.feather import write_feather, read_feather\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# get file paths of object detection results\n",
    "wdir = Path('/home/yu/OneDrive/Construal')\n",
    "os.chdir(wdir)\n",
    "\n",
    "p = wdir/'data/v2/v3det/on-train/per-image-objects/'\n",
    "files = list(p.glob('*.pt'))\n",
    "\n",
    "# img root directory\n",
    "img_root = Path('/home/yu/OneDrive/Construal/pretrained-models/v3det/data/V3Det/images')\n",
    "\n",
    "# loop over every image results\n",
    "obj_det_results = []\n",
    "for i, f in enumerate(tqdm(files)):\n",
    "    # load the results\n",
    "    df = torch.load(f)\n",
    "\n",
    "    # get size of each object\n",
    "    obj_size = [w*h for x, y, w, h in df['bboxes']]\n",
    "\n",
    "    # get the image path\n",
    "    img_path = img_root/f'{f.stem.split(\"-\")[0]}/{f.stem.split(\"-\")[1]}.jpg'\n",
    "    if not img_path.exists():\n",
    "        continue\n",
    "\n",
    "    # get the image size\n",
    "    with Image.open(img_path) as img:\n",
    "        w, h = img.size\n",
    "        img_size = w * h\n",
    "\n",
    "    # get the ratio of each object\n",
    "    obj_size_ratio = [x/img_size for x in obj_size]\n",
    "    \n",
    "    # collect the results into a dataframe\n",
    "    df = pd.DataFrame(\n",
    "        {'pid': f.stem, 'label': df['labels'], 'score': df['scores'], \n",
    "         'size_ratio': obj_size_ratio})\n",
    "    obj_det_results.append(df)\n",
    "\n",
    "# covert to dataframe\n",
    "obj_det_results = pd.concat(obj_det_results, ignore_index=True)\n",
    "obj_det_results['label'] = obj_det_results['label'].astype(int) + 1\n",
    "write_feather(obj_det_results, 'data/v2/v3det/on-train/obj_det_results.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniqueness (frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get object-level freq (Kickstarter)\n",
    "\n",
    "Compute object frequency where the context is limited two kickstarter product categories: \"product design\" and \"accessories.\"\n",
    "\n",
    "**Attention!**\n",
    "\n",
    "The label IDs outputed by MMdet are indexed from 0 (i.e., 0, 1, 2...) but the official category list is indexed from 1. To align the two, we need to add one to each of the predicted ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages({\n",
    "    library(arrow)\n",
    "})\n",
    "\n",
    "wdir = '/home/yu/OneDrive/Construal/'\n",
    "setwd(wdir)\n",
    "\n",
    "# we set the threshold of probability to be 0.1 or 0.5 (we tried two versions)\n",
    "score_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of object categories: 194\"\n",
      "[1] \"Number of projects: 873\"\n"
     ]
    }
   ],
   "source": [
    "# read detection results\n",
    "obj_det_results = read_feather(\n",
    "    'data/v2/v3det/on-kickstarter/obj_det_results.feather',\n",
    "    col_select=c('pid', 'label', 'score')) %>% setDT()\n",
    "\n",
    "# we only keep the results with score >= score_threshold\n",
    "# and then compute frequency\n",
    "freq = obj_det_results[\n",
    "    score >= score_threshold,\n",
    "    .(freq=.N),\n",
    "    keyby=.(label)\n",
    "    # normalize the largest freq to 1\n",
    "    ][, ':='(freq=freq/max(freq))]\n",
    "\n",
    "# print number of object categories\n",
    "print(sprintf('Number of object categories: %d', nrow(freq)))\n",
    "\n",
    "# print number of projects\n",
    "print(sprintf('Number of projects: %d', obj_det_results[score>=score_threshold, uniqueN(pid)]))\n",
    "\n",
    "# add category name\n",
    "cat_info = read_feather('data/v2/v3det/category_info.feather') %>% setDT()\n",
    "\n",
    "freq = freq[\n",
    "    cat_info[, .(id, name)], \n",
    "    on=c('label==id'), nomatch=NULL\n",
    "    ][order(-freq)]\n",
    "\n",
    "# save the frequency table\n",
    "write_feather(freq, sprintf('data/v2/v3det/on-kickstarter/freq_p%s.feather', score_threshold*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get object-level frequency (V3D)\n",
    "\n",
    "Compute object frequency where the context is the whole training dataset of V3D.\n",
    "\n",
    "**Attention!**\n",
    "\n",
    "The label IDs outputed by MMdet are indexed from 0 (i.e., 0, 1, 2...) but the official category list is indexed from 1. To align the two, we need to add one to each of the predicted ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of object categories: 12913\"\n",
      "[1] \"Number of projects: 209308\"\n"
     ]
    }
   ],
   "source": [
    "suppressMessages({\n",
    "    library(arrow)\n",
    "})\n",
    "\n",
    "wdir = '/home/yu/OneDrive/Construal/'\n",
    "setwd(wdir)\n",
    "\n",
    "# we set the threshold of probability (for V3D training datset) to be 0.5 \n",
    "# (we don't use 0.1 becaue using 0.5 will still give us enough data)\n",
    "score_threshold = 0.5\n",
    "\n",
    "# read detection results\n",
    "obj_det_results = read_feather(\n",
    "    'data/v2/v3det/on-train/obj_det_results.feather',\n",
    "    col_select=c('img_name', 'label', 'score')) %>% setDT()\n",
    "\n",
    "# we set the score threashold to 0.5 (typicall value is 0.5 to 0.95) and compute frequency\n",
    "freq = obj_det_results[\n",
    "    score >= score_threshold,\n",
    "    .(freq=.N),\n",
    "    keyby=.(label)\n",
    "    # normalize the largest freq to 1\n",
    "    ][, ':='(freq=freq/max(freq))]\n",
    "\n",
    "# print number of object categories\n",
    "print(sprintf('Number of object categories: %d', nrow(freq)))\n",
    "\n",
    "# print number of images left\n",
    "print(sprintf('Number of projects: %d', obj_det_results[score>=score_threshold, uniqueN(img_name)]))\n",
    "\n",
    "# add category name\n",
    "cat_info = read_feather('data/v2/v3det/category_info.feather') %>% setDT()\n",
    "\n",
    "freq = freq[\n",
    "    cat_info[, .(id, name)], \n",
    "    on=c('label==id'), nomatch=NULL\n",
    "    ][order(-freq)]\n",
    "\n",
    "# save the frequency table\n",
    "write_feather(freq, sprintf('data/v2/v3det/on-train/freq_p%s.feather', score_threshold*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get project-level frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of projects: 3704\"\n"
     ]
    }
   ],
   "source": [
    "# we set the threshold of probability to be 0.1 or 0.5\n",
    "score_threshold = 0.1\n",
    "\n",
    "# load the object-level frequency table (Kick- and V3D-context)\n",
    "freq_kick = read_feather(\n",
    "    sprintf('data/v2/v3det/on-kickstarter/freq_p%s.feather', score_threshold*100), \n",
    "    col_select=c('label', 'freq')) %>% setDT()\n",
    "\n",
    "freq_v3d = read_feather(\n",
    "    # for v3d, we only use one threahold (0.5)\n",
    "    'data/v2/v3det/on-train/freq_p50.feather', \n",
    "    col_select=c('label', 'freq')) %>% setDT()\n",
    "\n",
    "setnames(freq_kick, 'freq', 'freq_kick')\n",
    "setnames(freq_v3d, 'freq', 'freq_v3d')\n",
    "\n",
    "# combine the two frequency tables into one, `freq`\n",
    "freq = freq_kick[freq_v3d, on=c('label'), nomatch=NULL]\n",
    "\n",
    "# load the object detection results\n",
    "obj_det_results = read_feather('data/v2/v3det/on-kickstarter/obj_det_results.feather') %>% setDT()\n",
    "\n",
    "# we only keep objects with score >= score_threshold\n",
    "obj_det_results = obj_det_results[score>=score_threshold]\n",
    "\n",
    "# compute the freq of each project\n",
    "# by aggregating the freq of each object in the project\n",
    "proj_freq = obj_det_results[\n",
    "    freq, on=.(label), nomatch=NULL\n",
    "    # two versions: simple average and weighted avg by probability\n",
    "    ][, .(freq_kick=sum(freq_kick), freq_kick_w=sum(freq_kick*score),\n",
    "          freq_v3d=sum(freq_v3d), freq_v3d_w=sum(freq_v3d*score)),\n",
    "    keyby=.(pid)]\n",
    "\n",
    "# print the number of projects left\n",
    "print(sprintf('Number of projects: %d', uniqueN(proj_freq$pid)))\n",
    "\n",
    "write_feather(proj_freq, sprintf('data/v2/proj_freq_p%s.feather', score_threshold*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readability\n",
    "\n",
    "Compute the 1) number of objects, and 2) size (area) of each object\n",
    "\n",
    "Unlike \"uniqueness,\" readability does not differentiate between V3D context or Kick context because the computation purely relies on the attribute of the image itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages({\n",
    "    library(arrow)\n",
    "})\n",
    "\n",
    "wdir = '/home/yu/OneDrive/Construal/'\n",
    "setwd(wdir)\n",
    "\n",
    "# Run the whole cell two times, one with `score_threshold=0.1` \n",
    "# and one with `score_threshold=0.5`\n",
    "score_threshold = 0.5\n",
    "\n",
    "# read obj detection results of kickstart projects\n",
    "obj_det_results = read_feather(\n",
    "    'data/v2/v3det/on-kickstarter/obj_det_results.feather') %>% setDT()\n",
    "\n",
    "# we only keep the results with score >= score_threshold\n",
    "# and then compute frequency\n",
    "readability = obj_det_results[\n",
    "    score >= score_threshold\n",
    "    ][, .(\n",
    "    # compute object number\n",
    "      obj_num=.N, obj_num_w=sum(score),\n",
    "    # compute object size\n",
    "      obj_size_lt_5=sum(size_ratio<=0.05),\n",
    "      obj_size_lt_10=sum(size_ratio<=0.1),\n",
    "      obj_size_lt_20=sum(size_ratio<=0.2), \n",
    "      obj_size_lt_50=sum(size_ratio<=0.5),\n",
    "      obj_size_w_lt_5=sum((score*size_ratio)<=0.05),\n",
    "      obj_size_w_lt_10=sum((score*size_ratio)<=0.1),\n",
    "      obj_size_w_lt_20=sum((score*size_ratio)<=0.2),\n",
    "      obj_size_w_lt_50=sum((score*size_ratio)<=0.5)\n",
    "    ), \n",
    "    keyby=.(pid)]\n",
    "\n",
    "# print number of projects\n",
    "print(sprintf('Number of projects: %d', uniqueN(readability$pid)))\n",
    "\n",
    "# save the readability table\n",
    "write_feather(readability, sprintf('data/v2/proj_read_p%s.feather', score_threshold*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNI concreteness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from IPython.utils import io\n",
    "from pathlib import Path\n",
    "from pyarrow.feather import write_feather, read_feather\n",
    "from tqdm import tqdm\n",
    "\n",
    "wdir = Path('/home/yu/OneDrive/Construal')\n",
    "os.chdir(wdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Per-image Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Get the embeddings of images. It's done by `v3d-img-embed-on-kickstarter.py` and `v3d-img-embed-on-train.py`.\n",
    "\n",
    "The output is stored at `data/v2/v3det/on-kickstarter/per-image-embed` and `data/v2/v3det/on-train/per-image-embed`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect Results into a Dict (Kickstarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every image in the Kickstarter has its own embedding stored as a `.pt` file. We collect and combine them into a single dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3749 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3749/3749 [00:00<00:00, 8558.85it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_root = Path('data/v2/v3det/on-kickstarter/per-image-embed')\n",
    "emb_paths = list(emb_root.glob('*.pt'))\n",
    "\n",
    "# initialize a dictionary to store embeddings\n",
    "# key: pid, value: embedding tensor\n",
    "emb_dict = {}\n",
    "\n",
    "# load embeddings\n",
    "for i, path in enumerate(tqdm(emb_paths)):\n",
    "    emb_dict[path.stem] = torch.load(path)\n",
    "\n",
    "# save embeddings\n",
    "torch.save(emb_dict, 'data/v2/v3det/on-kickstarter/img_emb_results.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect Results into a Dict (V3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every image in the training set of V3D has its own embedding stored as a `.pt` file. We collect and combine them into a single dictory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213055/213055 [00:22<00:00, 9338.61it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_root = Path('data/v2/v3det/on-train/per-image-embed')\n",
    "emb_paths = list(emb_root.glob('*.pt'))\n",
    "\n",
    "# initialize a dictionary to store embeddings\n",
    "# key: pid, value: embedding tensor\n",
    "emb_dict = {}\n",
    "\n",
    "# load embeddings\n",
    "for i, path in enumerate(tqdm(emb_paths)):\n",
    "    emb_dict[path.stem] = torch.load(path)\n",
    "\n",
    "# save embeddings\n",
    "torch.save(emb_dict, 'data/v2/v3det/on-train/img_emb_results.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get object-level MNI (Kickstarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To compute MNI, we first compute the MNI score of every **object category**, $MNI_{obj}$. \n",
    "\n",
    "We only use the **Kickstarter images** (i.e., context dependant) in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Build annoy tree --- #\n",
    "\n",
    "# Load image embeddings into an annoy tree\n",
    "embeds = torch.load(f'{wdir}/data/v2/v3det/on-kickstarter/img_emb_results.pt')\n",
    "valid_pids = list(embeds.keys())\n",
    "\n",
    "# load image reprs into an annoy tree\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "# initialize annoy tree \"t\"\n",
    "t = AnnoyIndex(1024, 'angular')\n",
    "\n",
    "# a map from pid to an int index\n",
    "img2id = {}\n",
    "\n",
    "for i, (img, vec) in enumerate(embeds.items()): \n",
    "\n",
    "    # create a map from pid to an int index\n",
    "    img2id[img] = i\n",
    "\n",
    "    # add image embeddings to annoy tree\n",
    "    t.add_item(i, vec)\n",
    "    \n",
    "# build annoy tree\n",
    "\n",
    "# set seed\n",
    "t.set_seed(42)\n",
    "\n",
    "# n_trees is the number of hyperplans splits we want to build\n",
    "# 10 to 100 is a good starting point of n_trees, but since we only have 3k images \n",
    "# in kickstarter, we can build more trees (i.e., 1000)\n",
    "t.build(n_trees=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique objects: 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:01<00:00, 127.00it/s]\n",
      "100%|██████████| 194/194 [00:02<00:00, 96.35it/s] \n",
      "100%|██████████| 194/194 [00:02<00:00, 69.36it/s] \n",
      "100%|██████████| 194/194 [00:04<00:00, 45.44it/s] \n"
     ]
    }
   ],
   "source": [
    "# --- Compute MNI (for different K neighbors) --- #\n",
    "\n",
    "# we set the threshold of probability to be 0.1 or 0.5\n",
    "score_threshold = 0.5\n",
    "\n",
    "\n",
    "# load object detection results\n",
    "obj_det_results = read_feather(wdir/'data/v2/v3det/on-kickstarter/obj_det_results.feather')\n",
    "\n",
    "# we only keep objects with probability >= 0.1 (0.5 only leaves us about 870)\n",
    "# this gives us about 3k object categories\n",
    "obj_det_results = obj_det_results[obj_det_results.score>=score_threshold]\n",
    "\n",
    "# get a list of all unique objects, `objs`\n",
    "# each element in `objs` is an integer ID for an object category\n",
    "objs = obj_det_results.label.unique().tolist()\n",
    "print(f'Number of unique objects: {len(objs)}')\n",
    "\n",
    "# get total number of images \n",
    "# the `V` in the formula, which is used to normalize MNI\n",
    "V = len(valid_pids)\n",
    "\n",
    "# main function to compute MNI\n",
    "def make_mni(k, t, search_k=-1):\n",
    "    '''\n",
    "    Args:\n",
    "        k: number of nearest neighbors\n",
    "        t: a compiled annoy tree\n",
    "        search_k: number of nodes to search (see doc of annoy)\n",
    "            default search_k = -1 (full search, = n_trees * k)\n",
    "    '''\n",
    "    \n",
    "    # initialize a dictionary to store mni\n",
    "    mni_dict = {}\n",
    "\n",
    "    # compute mni for each object category\n",
    "    for i, obj in enumerate(tqdm(objs)):\n",
    "\n",
    "        # `obj` is an integer ID for an object category\n",
    "\n",
    "        # get a list of all images (named by its pid) that contain `obj`\n",
    "        V_obj = obj_det_results[obj_det_results.label==obj].pid.unique().tolist()\n",
    "\n",
    "        # convert this list of pids to a list of int indices\n",
    "        # remember that `pid2id` is a map from pid to an int index\n",
    "        V_obj = [img2id[pid] for pid in V_obj]\n",
    "        V_obj = set(V_obj)\n",
    "        \n",
    "        # compute mni\n",
    "        a = 0\n",
    "        for v in V_obj:\n",
    "            # `v` is an int index for an image\n",
    "\n",
    "            # get a list of k nearest neighbors (named by its int indices) \n",
    "            # for `v` (excluding `v` itself)\n",
    "            NN_v = set(t.get_nns_by_item(v, k, search_k=search_k)) - set([v])\n",
    "\n",
    "            # get the number of images that contain `obj` and are also in `NN_v`\n",
    "            a += len(V_obj.intersection(NN_v))\n",
    "\n",
    "        # divide by the total number of images that contain `obj`\n",
    "        mni_obj = a/len(V_obj)\n",
    "\n",
    "        # normalize mni\n",
    "        adj_mni = mni_obj / (len(V_obj)*k) * V\n",
    "\n",
    "        mni_dict[obj] = adj_mni\n",
    "\n",
    "    df = pd.DataFrame(mni_dict.items(), columns=['obj', 'mni'])\n",
    "\n",
    "    return df\n",
    "\n",
    "obj_mni_k10 = make_mni(10, t)\n",
    "obj_mni_k25 = make_mni(25, t)\n",
    "obj_mni_k50 = make_mni(50, t)\n",
    "obj_mni_k100 = make_mni(100, t)\n",
    "\n",
    "obj_mni_k10.to_feather(wdir/f'data/v2/v3det/on-kickstarter/obj_mni_k10_p{int(score_threshold*100)}.feather')\n",
    "obj_mni_k25.to_feather(wdir/f'data/v2/v3det/on-kickstarter/obj_mni_k25_p{int(score_threshold*100)}.feather')\n",
    "obj_mni_k50.to_feather(wdir/f'data/v2/v3det/on-kickstarter/obj_mni_k50_p{int(score_threshold*100)}.feather')\n",
    "obj_mni_k100.to_feather(wdir/f'data/v2/v3det/on-kickstarter/obj_mni_k100_p{int(score_threshold*100)}.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get object-level MNI (V3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To compute MNI, we first compute the MNI score of every **object category**, $MNI_{obj}$. \n",
    "\n",
    "We only use the **V3D training data** (i.e., context independant) in this section.\n",
    "\n",
    "In the next section, we then compute the MNI of every project by aggregating the MNI \n",
    "scores of its containing objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213055/213055 [00:18<00:00, 11776.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Build annoy tree --- #\n",
    "\n",
    "# Load image embeddings into an annoy tree\n",
    "embeds = torch.load(f'{wdir}/data/v2/v3det/on-train/img_emb_results.pt')\n",
    "\n",
    "# get valid image names\n",
    "valid_imgs = list(embeds.keys())\n",
    "\n",
    "# load image reprs into an annoy tree\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "# initialize annoy tree \"t\"\n",
    "t = AnnoyIndex(1024, 'angular')\n",
    "\n",
    "# a map from image name to an int index\n",
    "img2id = {}\n",
    "\n",
    "# add embeddings to annoy tree\n",
    "for i, (img, vec) in enumerate(tqdm(embeds.items())): \n",
    "\n",
    "    # img is a string of the image name\n",
    "\n",
    "    # create a map from pid to an int index\n",
    "    img2id[img] = i\n",
    "\n",
    "    # add image embeddings to annoy tree\n",
    "    t.add_item(i, vec)\n",
    "    \n",
    "# build annoy tree\n",
    "# if search_k is fixed, then n_trees won't affect query time\n",
    "# 100 trees took about 35s to build\n",
    "t.build(n_trees=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute MNI (for different K neighbors) --- #\n",
    "\n",
    "# we set the threshold of probability to be 0.5 (for V3D training dataset we only use 0.5)\n",
    "score_threshold = 0.5\n",
    "\n",
    "\n",
    "# load object detection results\n",
    "obj_det_results = read_feather(wdir/'data/v2/v3det/on-train/obj_det_results.feather')\n",
    "\n",
    "# we only keep objects with probability >= 0.1 (0.5 only leaves us about 870)\n",
    "# this gives us about 3k object categories\n",
    "obj_det_results = obj_det_results[obj_det_results.score>=score_threshold]\n",
    "\n",
    "# get a list of all unique objects, `objs`\n",
    "# each element in `objs` is an integer ID for an object category\n",
    "objs = obj_det_results.label.unique().tolist()\n",
    "\n",
    "# get total number of images \n",
    "# the `V` in the formula, which is used to normalize MNI\n",
    "V = len(valid_imgs)\n",
    "\n",
    "# print the number of unique objects and images\n",
    "print(f'Number of unique objects: {len(objs)}')\n",
    "print(f'Number of images: {V}')\n",
    "\n",
    "# main function to compute MNI\n",
    "def make_mni(k, t, search_k=-1):\n",
    "    '''\n",
    "    Args:\n",
    "        k: number of nearest neighbors\n",
    "        t: a compiled annoy tree\n",
    "        search_k: number of nodes to search (see doc of annoy)\n",
    "    '''\n",
    "    \n",
    "    # initialize a dictionary to store mni\n",
    "    mni_dict = {}\n",
    "\n",
    "    # compute mni for each object category\n",
    "    for i, obj in enumerate(tqdm(objs)):\n",
    "\n",
    "        # `obj` is an integer ID for an object category\n",
    "\n",
    "        # get a list of all images (named by its img_name) that contain `obj`\n",
    "        V_obj = obj_det_results[obj_det_results.label==obj].img_name.unique().tolist()\n",
    "\n",
    "        # convert this list of pids to a list of int indices\n",
    "        # remember that `pid2id` is a map from pid to an int index\n",
    "        V_obj = [img2id[pid] for pid in V_obj]\n",
    "        V_obj = set(V_obj)\n",
    "        \n",
    "        # compute mni\n",
    "        a = 0\n",
    "        for v in V_obj:\n",
    "            # `v` is an int index for an image\n",
    "\n",
    "            # get a list of k nearest neighbors (named by its int indices) \n",
    "            # for `v` (excluding `v` itself)\n",
    "            NN_v = set(t.get_nns_by_item(v, k, search_k=search_k)) - set([v])\n",
    "\n",
    "            # get the number of images that contain `obj` and are also in `NN_v`\n",
    "            a += len(V_obj.intersection(NN_v))\n",
    "\n",
    "        # divide by the total number of images that contain `obj`\n",
    "        mni_obj = a/len(V_obj)\n",
    "\n",
    "        # normalize mni\n",
    "        adj_mni = mni_obj / (len(V_obj)*k) * V\n",
    "\n",
    "        mni_dict[obj] = adj_mni\n",
    "\n",
    "    df = pd.DataFrame(mni_dict.items(), columns=['obj', 'mni'])\n",
    "\n",
    "    return df\n",
    "\n",
    "obj_mni_k10 = make_mni(10, t)\n",
    "obj_mni_k25 = make_mni(25, t)\n",
    "obj_mni_k50 = make_mni(50, t)\n",
    "obj_mni_k100 = make_mni(100, t)\n",
    "\n",
    "obj_mni_k10.to_feather(wdir/f'data/v2/v3det/on-train/obj_mni_k10_p{int(score_threshold*100)}.feather')\n",
    "obj_mni_k25.to_feather(wdir/f'data/v2/v3det/on-train/obj_mni_k25_p{int(score_threshold*100)}.feather')\n",
    "obj_mni_k50.to_feather(wdir/f'data/v2/v3det/on-train/obj_mni_k50_p{int(score_threshold*100)}.feather')\n",
    "obj_mni_k100.to_feather(wdir/f'data/v2/v3det/on-train/obj_mni_k100_p{int(score_threshold*100)}.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get project-level MNI\n",
    "\n",
    "In the previous section, we've computed $MNI_obj$ for each object. Now we compute the MNI for the whole image (project). The project-level MNI is an aggregation of all the MNIs of the containing objects in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages({\n",
    "    library(arrow)\n",
    "})\n",
    "wdir = '/home/yu/OneDrive/Construal'\n",
    "setwd(wdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set the threshold of probability to be 0.1 or 0.5\n",
    "score_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of unique objects: 194\"\n"
     ]
    }
   ],
   "source": [
    "# -- load all object-level MNI into one dataset --\n",
    "\n",
    "# load MNI based on kickstarter\n",
    "obj_mni_k10_kick = read_feather(sprintf(\"data/v2/v3det/on-kickstarter/obj_mni_k10_p%s.feather\", score_threshold*100)) %>% setDT()\n",
    "obj_mni_k25_kick = read_feather(sprintf(\"data/v2/v3det/on-kickstarter/obj_mni_k25_p%s.feather\", score_threshold*100)) %>% setDT()\n",
    "obj_mni_k50_kick = read_feather(sprintf(\"data/v2/v3det/on-kickstarter/obj_mni_k50_p%s.feather\", score_threshold*100)) %>% setDT()\n",
    "obj_mni_k100_kick = read_feather(sprintf(\"data/v2/v3det/on-kickstarter/obj_mni_k100_p%s.feather\", score_threshold*100)) %>% setDT()\n",
    "\n",
    "# load MNI based on V3D (for V3D we only use one threshold, 0.5)\n",
    "obj_mni_k10_v3d = read_feather(\"data/v2/v3det/on-train/obj_mni_k10_p50.feather\") %>% setDT()\n",
    "obj_mni_k25_v3d = read_feather(\"data/v2/v3det/on-train/obj_mni_k25_p50.feather\") %>% setDT()\n",
    "obj_mni_k50_v3d = read_feather(\"data/v2/v3det/on-train/obj_mni_k50_p50.feather\") %>% setDT()\n",
    "obj_mni_k100_v3d = read_feather(\"data/v2/v3det/on-train/obj_mni_k100_p50.feather\") %>% setDT()\n",
    "\n",
    "setnames(obj_mni_k10_kick, 'mni', 'mni_k10_kick')\n",
    "setnames(obj_mni_k25_kick, 'mni', 'mni_k25_kick')\n",
    "setnames(obj_mni_k50_kick, 'mni', 'mni_k50_kick')\n",
    "setnames(obj_mni_k100_kick, \"mni\", \"mni_k100_kick\")\n",
    "\n",
    "setnames(obj_mni_k10_v3d, \"mni\", \"mni_k10_v3d\")\n",
    "setnames(obj_mni_k25_v3d, \"mni\", \"mni_k25_v3d\")\n",
    "setnames(obj_mni_k50_v3d, \"mni\", \"mni_k50_v3d\")\n",
    "setnames(obj_mni_k100_v3d, \"mni\", \"mni_k100_v3d\")\n",
    "\n",
    "# merge all MNI datasets\n",
    "obj_mni = obj_mni_k10_kick[\n",
    "    obj_mni_k25_kick, on=.(obj), nomatch=NULL\n",
    "    ][obj_mni_k50_kick, on=.(obj), nomatch=NULL\n",
    "    ][obj_mni_k100_kick, on=.(obj), nomatch=NULL\n",
    "    ][obj_mni_k10_v3d, on=.(obj), nomatch=NULL\n",
    "    ][obj_mni_k25_v3d, on=.(obj), nomatch=NULL\n",
    "    ][obj_mni_k50_v3d, on=.(obj), nomatch=NULL\n",
    "    ][obj_mni_k100_v3d, on=.(obj), nomatch=NULL]\n",
    "\n",
    "# print the number of unique objects\n",
    "sprintf(\"Number of unique objects: %d\", obj_mni[, uniqueN(obj)]) %>% print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of unique projects: 873\"\n"
     ]
    }
   ],
   "source": [
    "# --- compute project-level MNI --- #\n",
    "\n",
    "# read detection results\n",
    "obj_det_results = read_feather(\n",
    "    'data/v2/v3det/on-kickstarter/obj_det_results.feather',\n",
    "    col_select=c('pid', 'label', 'score')) %>% setDT()\n",
    "\n",
    "obj_det_results = obj_det_results[score>=score_threshold]\n",
    "\n",
    "# compute project-level MNI\n",
    "proj_mni = obj_det_results[\n",
    "    # add object-level MNI\n",
    "    obj_mni, on=c('label==obj'), nomatch=NULL\n",
    "    # compute project-level MNI\n",
    "    ][, .(\n",
    "        # kick-context\n",
    "        mni_k10_kick=sum(mni_k10_kick), mni_k25_kick=sum(mni_k25_kick),\n",
    "        mni_k50_kick=sum(mni_k50_kick), mni_k100_kick=sum(mni_k100_kick),\n",
    "        mni_k10_kick_w=sum(mni_k10_kick*score), mni_k25_kick_w=sum(mni_k25_kick*score),\n",
    "        mni_k50_kick_w=sum(mni_k50_kick*score), mni_k100_kick_w=sum(mni_k100_kick*score),\n",
    "        # v3d-context\n",
    "        mni_k10_v3d=sum(mni_k10_v3d), mni_k25_v3d=sum(mni_k25_v3d),\n",
    "        mni_k50_v3d=sum(mni_k50_v3d), mni_k100_v3d=sum(mni_k100_v3d),\n",
    "        mni_k10_v3d_w=sum(mni_k10_v3d*score), mni_k25_v3d_w=sum(mni_k25_v3d*score),\n",
    "        mni_k50_v3d_w=sum(mni_k50_v3d*score), mni_k100_v3d_w=sum(mni_k100_v3d*score)\n",
    "    ),\n",
    "    keyby=.(pid)]\n",
    "\n",
    "# save the project-level MNI\n",
    "write_feather(proj_mni, sprintf('data/v2/proj_mni_p%s.feather', score_threshold*100))\n",
    "\n",
    "# print the number of unique projects\n",
    "sprintf(\"Number of unique projects: %d\", proj_mni[, uniqueN(pid)]) %>% print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages({\n",
    "    library(arrow)\n",
    "})\n",
    "wdir = '/home/yu/OneDrive/Construal'\n",
    "setwd(wdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of unique projects: 3704\"\n",
      "[1] \"Number of unique projects: 873\"\n"
     ]
    }
   ],
   "source": [
    "combine_all <- function(score_threshold) {\n",
    "    # Args:\n",
    "    #    score_threshold: the threshold of probability (0.1 or 0.5)\n",
    "\n",
    "    # load mni, frequency, and readability\n",
    "    proj_mni = read_feather(sprintf('data/v2/proj_mni_p%s.feather', score_threshold*100)) %>% setDT()\n",
    "    proj_freq = read_feather(sprintf('data/v2/proj_freq_p%s.feather', score_threshold*100)) %>% setDT()\n",
    "    proj_read = read_feather(sprintf('data/v2/proj_read_p%s.feather', score_threshold*100)) %>% setDT()\n",
    "\n",
    "    # merge them into one\n",
    "    proj_metrics = proj_mni[\n",
    "        proj_freq, on=.(pid), nomatch=NULL\n",
    "        ][proj_read, on=.(pid), nomatch=NULL]\n",
    "\n",
    "    # print the number of unique projects\n",
    "    sprintf(\"Number of unique projects: %d\", proj_metrics[, uniqueN(pid)]) %>% print()\n",
    "\n",
    "    # save the dataset\n",
    "    write_feather(proj_metrics, sprintf('data/v2/proj_metrics_p%s.feather', score_threshold*100))\n",
    "\n",
    "    # print one row\n",
    "    proj_metrics[1]\n",
    "\n",
    "}\n",
    "\n",
    "proj_metrics_p10 = combine_all(0.1)\n",
    "proj_metrics_p10 = combine_all(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Ad hoc) Compute Metrics for 100 V3D Training Images\n",
    "\n",
    "**Update 2023-12-7**\n",
    "\n",
    "In the last update, I sample 100 images from V3D. However, because we're using some thresholds to filter identified objects, there're only 28 remaining images eligible for analysis. In this update, I first sample 1000 V3D training images. Then I compute the metrics for *all* of them. This guarantees that we'll have 100 remaining images.\n",
    "\n",
    "**Created**: 2023-11-29\n",
    "\n",
    "Previously, I randomly sampled approximately 100 images from the V3D training dataset for use in Amrita's human subject survey. However, we later find that we should sample images from the kickstarter projects, not the V3D training set. Since we already have run the survey on the 100 V3D images, Tianyu suggested that we proceed to compute the metrics for them regardless.\n",
    "\n",
    "The sampled images are under directory `data/sharing/v3det-image-examples`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run object detection\n",
    "\n",
    "Run object detection on the 100 images. The code is adapted from `v3d-obj-detect-on-kickstarter.py`.\n",
    "\n",
    "The results is saved under directory `data/v2/v3det/on-[100|5000]-sampled-kick-images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from mmdet.apis import DetInferencer\n",
    "from IPython.utils import io\n",
    "from tqdm import tqdm\n",
    "from pyarrow.feather import write_feather, read_feather\n",
    "\n",
    "wdir = Path('/home/yu/OneDrive/Construal')\n",
    "os.chdir(wdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 2600.06it/s]\n"
     ]
    }
   ],
   "source": [
    "#--- Randomly sample 5000 images from V3D training dataset ---#\n",
    "\n",
    "image_root = Path('/home/yu/OneDrive/Construal/pretrained-models/v3det/data/V3Det/images')\n",
    "image_paths = list(image_root.glob('./*/*.jpg'))\n",
    "\n",
    "# Set the random seed\n",
    "random.seed(42)\n",
    "\n",
    "# Number of elements to sample\n",
    "N = 5000\n",
    "\n",
    "# Randomly sample N elements from the list\n",
    "image_paths = random.sample(image_paths, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/yu/OneDrive/Construal/pretrained-models/v3det/checkpoints/Deformable_DETR_V3Det_SwinB.pth\n",
      "12/07 15:12:37 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/Software/python/python-env/py311-mmdet/lib/python3.11/site-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n",
      "100%|██████████| 5000/5000 [11:36<00:00,  7.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#--- Using V3Det to detect objects in images, run on 100 sampled V3D images ---#\n",
    "\n",
    "# change working directory\n",
    "model_dir = Path('/home/yu/OneDrive/Construal/pretrained-models/v3det')\n",
    "os.chdir(model_dir)\n",
    "\n",
    "# Initialize the DetInferencer\n",
    "inferencer = DetInferencer(\n",
    "    # DETR (DETR is faster)\n",
    "    model='/home/yu/OneDrive/Construal/pretrained-models/v3det/checkpoints/configs/v3det/deformable-detr-refine-twostage_swin_16xb2_sample1e-3_v3det_50e.py',\n",
    "    weights='/home/yu/OneDrive/Construal/pretrained-models/v3det/checkpoints/Deformable_DETR_V3Det_SwinB.pth',\n",
    "\n",
    "    device='cuda:1'\n",
    ")\n",
    "\n",
    "# inference\n",
    "for i, img_path in enumerate(tqdm(image_paths)):\n",
    "\n",
    "    # get image name and folder\n",
    "    img_name = img_path.stem\n",
    "    img_folder = img_path.parent.stem\n",
    "    \n",
    "    # skip if image not exist\n",
    "    if not img_path.exists():\n",
    "        print(f'{img_path} does not exist')\n",
    "        continue\n",
    "\n",
    "    # inference\n",
    "    # the model only keep the top 300 predictions (with the highest confidence)\n",
    "    with io.capture_output() as captured:\n",
    "        out = inferencer(str(img_path), show=False)['predictions'][0]\n",
    "\n",
    "    # save results\n",
    "    torch.save(out, wdir/f'data/v2/v3det/on-5000-sampled-v3d-images/per-image-objects/{img_folder}-{img_name}.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file paths of object detection results\n",
    "wdir = Path('/home/yu/OneDrive/Construal')\n",
    "os.chdir(wdir)\n",
    "\n",
    "p = wdir/'data/v2/v3det/on-5000-sampled-v3d-images/per-image-objects/'\n",
    "files = list(p.glob('*.pt'))\n",
    "\n",
    "# img root directory\n",
    "img_root = Path('/home/yu/OneDrive/Construal/pretrained-models/v3det/data/V3Det/images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1722.06it/s]\n"
     ]
    }
   ],
   "source": [
    "#--- Collect per-image results into one dataframe ---#\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.utils import io\n",
    "from pyarrow.feather import write_feather, read_feather\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# get file paths of object detection results\n",
    "wdir = Path('/home/yu/OneDrive/Construal')\n",
    "os.chdir(wdir)\n",
    "\n",
    "p = wdir/'data/v2/v3det/on-5000-sampled-v3d-images/per-image-objects/'\n",
    "files = list(p.glob('*.pt'))\n",
    "\n",
    "# img root directory\n",
    "img_root = Path('/home/yu/OneDrive/Construal/pretrained-models/v3det/data/V3Det/images')\n",
    "\n",
    "# loop over every image results\n",
    "obj_det_results = []\n",
    "for i, f in enumerate(tqdm(files)):\n",
    "    # load the results\n",
    "    df = torch.load(f)\n",
    "\n",
    "    # get size of each object\n",
    "    obj_size = [w*h for x, y, w, h in df['bboxes']]\n",
    "\n",
    "    # get the image path\n",
    "    img_path = img_root/f'{f.stem.split(\"-\")[0]}/{f.stem.split(\"-\")[1]}.jpg'\n",
    "    if not img_path.exists():\n",
    "        continue\n",
    "\n",
    "    # get the image size\n",
    "    with Image.open(img_path) as img:\n",
    "        w, h = img.size\n",
    "        img_size = w * h\n",
    "\n",
    "    # get the ratio of each object\n",
    "    obj_size_ratio = [x/img_size for x in obj_size]\n",
    "    \n",
    "    # collect the results into a dataframe\n",
    "    df = pd.DataFrame(\n",
    "        {'pid': f.stem, 'label': df['labels'], 'score': df['scores'], \n",
    "         'size_ratio': obj_size_ratio})\n",
    "    obj_det_results.append(df)\n",
    "\n",
    "# covert to dataframe\n",
    "obj_det_results = pd.concat(obj_det_results, ignore_index=True)\n",
    "obj_det_results['label'] = obj_det_results['label'].astype(int) + 1\n",
    "write_feather(obj_det_results, 'data/v2/v3det/on-5000-sampled-v3d-images/obj_det_results.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Uniqueness\n",
    "\n",
    "Because object-level scores have already been computed, we only need to compute project-level data here.\n",
    "\n",
    "`Naming`: we add the `100v3d` suffix to indicate the metrics are computed for the 100 sampled V3D images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages({\n",
    "    library(arrow)\n",
    "})\n",
    "\n",
    "wdir = '/home/yu/OneDrive/Construal/'\n",
    "setwd(wdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of projects: 3889\"\n"
     ]
    }
   ],
   "source": [
    "# Run the whole cell two time, one with `score_threshold=0.1` \n",
    "# and one with `score_threshold=0.5`\n",
    "score_threshold = 0.1\n",
    "\n",
    "# load the object-level frequency table (Kick- and V3D-context)\n",
    "freq_kick = read_feather(\n",
    "    sprintf('data/v2/v3det/on-kickstarter/freq_p%s.feather', score_threshold*100), \n",
    "    col_select=c('label', 'freq')) %>% setDT()\n",
    "\n",
    "freq_v3d = read_feather(\n",
    "    # for v3d, we only use one threahold (0.5)\n",
    "    'data/v2/v3det/on-train/freq_p50.feather', \n",
    "    col_select=c('label', 'freq')) %>% setDT()\n",
    "\n",
    "setnames(freq_kick, 'freq', 'freq_kick')\n",
    "setnames(freq_v3d, 'freq', 'freq_v3d')\n",
    "\n",
    "# combine the two frequency tables into one, `freq`\n",
    "freq = freq_kick[freq_v3d, on=c('label'), nomatch=NULL]\n",
    "\n",
    "# load the object detection results\n",
    "obj_det_results = read_feather('data/v2/v3det/on-5000-sampled-v3d-images/obj_det_results.feather') %>% setDT()\n",
    "\n",
    "# we only keep objects with score >= score_threshold\n",
    "obj_det_results = obj_det_results[score>=score_threshold]\n",
    "\n",
    "# compute the freq of each project\n",
    "# by aggregating the freq of each object in the project\n",
    "proj_freq = obj_det_results[\n",
    "    freq, on=.(label), nomatch=NULL\n",
    "    # two versions: simple average and weighted avg by probability\n",
    "    ][, .(freq_kick=sum(freq_kick), freq_kick_w=sum(freq_kick*score),\n",
    "          freq_v3d=sum(freq_v3d), freq_v3d_w=sum(freq_v3d*score)),\n",
    "    keyby=.(pid)]\n",
    "\n",
    "# print the number of projects left\n",
    "print(sprintf('Number of projects: %d', uniqueN(proj_freq$pid)))\n",
    "\n",
    "write_feather(proj_freq, sprintf('data/v2/proj_freq_p%s_5000v3d.feather', score_threshold*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Readability\n",
    "\n",
    "Because object-level scores have already been computed, we only need to compute project-level data here.\n",
    "\n",
    "`Naming`: we add the `100v3d` suffix to indicate the metrics are computed for the 100 sampled V3D images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nreadability = obj_det_results[\\n    score >= score_threshold\\n    ][, .(\\n    # compute object number\\n      obj_num=.N, obj_num_w=sum(score),\\n    # compute object size\\n      obj_size_lt_5=sum(size_ratio<=0.05),\\n      obj_size_lt_10=sum(size_ratio<=0.1),\\n      obj_size_lt_20=sum(size_ratio<=0.2), \\n      obj_size_lt_50=sum(size_ratio<=0.5),\\n      obj_size_w_lt_5=sum((score*size_ratio)<=0.05),\\n      obj_size_w_lt_10=sum((score*size_ratio)<=0.1),\\n      obj_size_w_lt_20=sum((score*size_ratio)<=0.2),\\n      obj_size_w_lt_50=sum((score*size_ratio)<=0.5)\\n    ), \\n    keyby=.(pid)]\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.utils import io\n",
    "from pyarrow.feather import write_feather, read_feather\n",
    "from tqdm import tqdm\n",
    "\n",
    "wdir = Path('/home/yu/OneDrive/Construal/')\n",
    "os.chdir(wdir)\n",
    "\n",
    "# Run the whole cell two times, one with `score_threshold=0.1` \n",
    "# and one with `score_threshold=0.5`\n",
    "score_threshold = 0.5\n",
    "\n",
    "# read obj detection results of kickstart projects\n",
    "obj_det_results = read_feather(\n",
    "    'data/v2/v3det/on-5000-sampled-v3d-images/obj_det_results.feather'\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "np.array\n",
    "\n",
    "'''\n",
    "readability = obj_det_results[\n",
    "    score >= score_threshold\n",
    "    ][, .(\n",
    "    # compute object number\n",
    "      obj_num=.N, obj_num_w=sum(score),\n",
    "    # compute object size\n",
    "      obj_size_lt_5=sum(size_ratio<=0.05),\n",
    "      obj_size_lt_10=sum(size_ratio<=0.1),\n",
    "      obj_size_lt_20=sum(size_ratio<=0.2), \n",
    "      obj_size_lt_50=sum(size_ratio<=0.5),\n",
    "      obj_size_w_lt_5=sum((score*size_ratio)<=0.05),\n",
    "      obj_size_w_lt_10=sum((score*size_ratio)<=0.1),\n",
    "      obj_size_w_lt_20=sum((score*size_ratio)<=0.2),\n",
    "      obj_size_w_lt_50=sum((score*size_ratio)<=0.5)\n",
    "    ), \n",
    "    keyby=.(pid)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_det_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q102248528-30_437_19147411343_2637cb5235_c</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1042016-33_1175_10107924916_8e80ce8bee_c</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1043002-19_1061_7884955554_290fa536cf_c</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1066566-26_475_2806916154_c050f2a34c_c</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q10742210-17_1489_18511995991_c244dcf715_c</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4622</th>\n",
       "      <td>x00001572-000191600</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>x00001574-000171052</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>x00001577-000107855</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>x00001581-000171352</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>x00001583-000171408</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4627 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             pid  score\n",
       "0     Q102248528-30_437_19147411343_2637cb5235_c    293\n",
       "1      Q1042016-33_1175_10107924916_8e80ce8bee_c    154\n",
       "2       Q1043002-19_1061_7884955554_290fa536cf_c    185\n",
       "3        Q1066566-26_475_2806916154_c050f2a34c_c     87\n",
       "4     Q10742210-17_1489_18511995991_c244dcf715_c     75\n",
       "...                                          ...    ...\n",
       "4622                         x00001572-000191600    277\n",
       "4623                         x00001574-000171052    249\n",
       "4624                         x00001577-000107855    283\n",
       "4625                         x00001581-000171352    278\n",
       "4626                         x00001583-000171408    206\n",
       "\n",
       "[4627 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_det_results.loc[obj_det_results.score <= 0.1] \\\n",
    "    .groupby(['pid'])['score'] \\\n",
    "    .count() \\\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of projects: 3570\"\n"
     ]
    }
   ],
   "source": [
    "suppressMessages({\n",
    "    library(arrow)\n",
    "})\n",
    "\n",
    "wdir = '/home/yu/OneDrive/Construal/'\n",
    "setwd(wdir)\n",
    "\n",
    "# Run the whole cell two times, one with `score_threshold=0.1` \n",
    "# and one with `score_threshold=0.5`\n",
    "score_threshold = 0.5\n",
    "\n",
    "# read obj detection results of kickstart projects\n",
    "obj_det_results = read_feather(\n",
    "    'data/v2/v3det/on-5000-sampled-v3d-images/obj_det_results.feather') %>% setDT()\n",
    "\n",
    "# we only keep the results with score >= score_threshold\n",
    "# and then compute frequency\n",
    "readability = obj_det_results[\n",
    "    score >= score_threshold\n",
    "    ][, .(\n",
    "    # compute object number\n",
    "      obj_num=.N, obj_num_w=sum(score),\n",
    "    # compute object size\n",
    "      obj_size_lt_5=sum(size_ratio<=0.05),\n",
    "      obj_size_lt_10=sum(size_ratio<=0.1),\n",
    "      obj_size_lt_20=sum(size_ratio<=0.2), \n",
    "      obj_size_lt_50=sum(size_ratio<=0.5),\n",
    "      obj_size_w_lt_5=sum((score*size_ratio)<=0.05),\n",
    "      obj_size_w_lt_10=sum((score*size_ratio)<=0.1),\n",
    "      obj_size_w_lt_20=sum((score*size_ratio)<=0.2),\n",
    "      obj_size_w_lt_50=sum((score*size_ratio)<=0.5)\n",
    "    ), \n",
    "    keyby=.(pid)]\n",
    "\n",
    "# print number of projects\n",
    "print(sprintf('Number of projects: %d', uniqueN(readability$pid)))\n",
    "\n",
    "# save the readability table\n",
    "write_feather(readability, sprintf('data/v2/proj_read_p%s_5000v3d.feather', score_threshold*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Concreteness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of unique objects: 194\"\n"
     ]
    }
   ],
   "source": [
    "# -- load all object-level MNI into one dataset --\n",
    "\n",
    "# load MNI based on kickstarter\n",
    "obj_mni_k10_kick = read_feather(sprintf(\"data/v2/v3det/on-kickstarter/obj_mni_k10_p%s.feather\", score_threshold*100)) %>% setDT()\n",
    "obj_mni_k25_kick = read_feather(sprintf(\"data/v2/v3det/on-kickstarter/obj_mni_k25_p%s.feather\", score_threshold*100)) %>% setDT()\n",
    "obj_mni_k50_kick = read_feather(sprintf(\"data/v2/v3det/on-kickstarter/obj_mni_k50_p%s.feather\", score_threshold*100)) %>% setDT()\n",
    "obj_mni_k100_kick = read_feather(sprintf(\"data/v2/v3det/on-kickstarter/obj_mni_k100_p%s.feather\", score_threshold*100)) %>% setDT()\n",
    "\n",
    "# load MNI based on V3D (for V3D we only use one threshold, 0.5)\n",
    "obj_mni_k10_v3d = read_feather(\"data/v2/v3det/on-train/obj_mni_k10_p50.feather\") %>% setDT()\n",
    "obj_mni_k25_v3d = read_feather(\"data/v2/v3det/on-train/obj_mni_k25_p50.feather\") %>% setDT()\n",
    "obj_mni_k50_v3d = read_feather(\"data/v2/v3det/on-train/obj_mni_k50_p50.feather\") %>% setDT()\n",
    "obj_mni_k100_v3d = read_feather(\"data/v2/v3det/on-train/obj_mni_k100_p50.feather\") %>% setDT()\n",
    "\n",
    "setnames(obj_mni_k10_kick, 'mni', 'mni_k10_kick')\n",
    "setnames(obj_mni_k25_kick, 'mni', 'mni_k25_kick')\n",
    "setnames(obj_mni_k50_kick, 'mni', 'mni_k50_kick')\n",
    "setnames(obj_mni_k100_kick, \"mni\", \"mni_k100_kick\")\n",
    "\n",
    "setnames(obj_mni_k10_v3d, \"mni\", \"mni_k10_v3d\")\n",
    "setnames(obj_mni_k25_v3d, \"mni\", \"mni_k25_v3d\")\n",
    "setnames(obj_mni_k50_v3d, \"mni\", \"mni_k50_v3d\")\n",
    "setnames(obj_mni_k100_v3d, \"mni\", \"mni_k100_v3d\")\n",
    "\n",
    "# merge all MNI datasets\n",
    "obj_mni = obj_mni_k10_kick[\n",
    "    obj_mni_k25_kick, on=.(obj), nomatch=NULL\n",
    "    ][obj_mni_k50_kick, on=.(obj), nomatch=NULL\n",
    "    ][obj_mni_k100_kick, on=.(obj), nomatch=NULL\n",
    "    ][obj_mni_k10_v3d, on=.(obj), nomatch=NULL\n",
    "    ][obj_mni_k25_v3d, on=.(obj), nomatch=NULL\n",
    "    ][obj_mni_k50_v3d, on=.(obj), nomatch=NULL\n",
    "    ][obj_mni_k100_v3d, on=.(obj), nomatch=NULL]\n",
    "\n",
    "# print the number of unique objects\n",
    "sprintf(\"Number of unique objects: %d\", obj_mni[, uniqueN(obj)]) %>% print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of unique projects: 2573\"\n"
     ]
    }
   ],
   "source": [
    "# --- compute project-level MNI --- #\n",
    "\n",
    "# Run the whole cell two times, one with `score_threshold=0.1` \n",
    "# and one with `score_threshold=0.5`\n",
    "score_threshold = 0.1\n",
    "\n",
    "# read detection results\n",
    "obj_det_results = read_feather(\n",
    "    'data/v2/v3det/on-5000-sampled-v3d-images/obj_det_results.feather',\n",
    "    col_select=c('pid', 'label', 'score')) %>% setDT()\n",
    "\n",
    "obj_det_results = obj_det_results[score>=score_threshold]\n",
    "\n",
    "# compute project-level MNI\n",
    "proj_mni = obj_det_results[\n",
    "    # add object-level MNI\n",
    "    obj_mni, on=c('label==obj'), nomatch=NULL\n",
    "    # compute project-level MNI\n",
    "    ][, .(\n",
    "        # kick-context\n",
    "        mni_k10_kick=sum(mni_k10_kick), mni_k25_kick=sum(mni_k25_kick),\n",
    "        mni_k50_kick=sum(mni_k50_kick), mni_k100_kick=sum(mni_k100_kick),\n",
    "        mni_k10_kick_w=sum(mni_k10_kick*score), mni_k25_kick_w=sum(mni_k25_kick*score),\n",
    "        mni_k50_kick_w=sum(mni_k50_kick*score), mni_k100_kick_w=sum(mni_k100_kick*score),\n",
    "        # v3d-context\n",
    "        mni_k10_v3d=sum(mni_k10_v3d), mni_k25_v3d=sum(mni_k25_v3d),\n",
    "        mni_k50_v3d=sum(mni_k50_v3d), mni_k100_v3d=sum(mni_k100_v3d),\n",
    "        mni_k10_v3d_w=sum(mni_k10_v3d*score), mni_k25_v3d_w=sum(mni_k25_v3d*score),\n",
    "        mni_k50_v3d_w=sum(mni_k50_v3d*score), mni_k100_v3d_w=sum(mni_k100_v3d*score)\n",
    "    ),\n",
    "    keyby=.(pid)]\n",
    "\n",
    "# save the project-level MNI\n",
    "write_feather(proj_mni, sprintf('data/v2/proj_mni_p%s_5000v3d.feather', score_threshold*100))\n",
    "\n",
    "# print the number of unique projects\n",
    "sprintf(\"Number of unique projects: %d\", proj_mni[, uniqueN(pid)]) %>% print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of unique projects: 2573\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of unique projects: 949\"\n"
     ]
    }
   ],
   "source": [
    "combine_all <- function(score_threshold) {\n",
    "    # Args:\n",
    "    #    score_threshold: the threshold of probability (0.1 or 0.5)\n",
    "\n",
    "    # load mni, frequency, and readability\n",
    "    proj_mni = read_feather(sprintf('data/v2/proj_mni_p%s_5000v3d.feather', score_threshold*100)) %>% setDT()\n",
    "    proj_freq = read_feather(sprintf('data/v2/proj_freq_p%s_5000v3d.feather', score_threshold*100)) %>% setDT()\n",
    "    proj_read = read_feather(sprintf('data/v2/proj_read_p%s_5000v3d.feather', score_threshold*100)) %>% setDT()\n",
    "\n",
    "    # merge them into one\n",
    "    proj_metrics = proj_mni[\n",
    "        proj_freq, on=.(pid), nomatch=NULL\n",
    "        ][proj_read, on=.(pid), nomatch=NULL]\n",
    "\n",
    "    # print the number of unique projects\n",
    "    sprintf(\"Number of unique projects: %d\", proj_metrics[, uniqueN(pid)]) %>% print()\n",
    "\n",
    "    # save the dataset\n",
    "    write_feather(proj_metrics, sprintf('data/v2/proj_metrics_p%s_5000v3d.feather', score_threshold*100))\n",
    "\n",
    "    # print one row\n",
    "    proj_metrics[1]\n",
    "\n",
    "    # return\n",
    "    proj_metrics\n",
    "\n",
    "}\n",
    "\n",
    "proj_metrics_p10 = combine_all(0.1)\n",
    "proj_metrics_p50 = combine_all(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 31</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>pid</th><th scope=col>mni_k10_kick</th><th scope=col>mni_k25_kick</th><th scope=col>mni_k50_kick</th><th scope=col>mni_k100_kick</th><th scope=col>mni_k10_kick_w</th><th scope=col>mni_k25_kick_w</th><th scope=col>mni_k50_kick_w</th><th scope=col>mni_k100_kick_w</th><th scope=col>mni_k10_v3d</th><th scope=col>mni_k25_v3d</th><th scope=col>mni_k50_v3d</th><th scope=col>mni_k100_v3d</th><th scope=col>mni_k10_v3d_w</th><th scope=col>mni_k25_v3d_w</th><th scope=col>mni_k50_v3d_w</th><th scope=col>mni_k100_v3d_w</th><th scope=col>freq_kick</th><th scope=col>freq_kick_w</th><th scope=col>freq_v3d</th><th scope=col>freq_v3d_w</th><th scope=col>obj_num</th><th scope=col>obj_num_w</th><th scope=col>obj_size_lt_5</th><th scope=col>obj_size_lt_10</th><th scope=col>obj_size_lt_20</th><th scope=col>obj_size_lt_50</th><th scope=col>obj_size_w_lt_5</th><th scope=col>obj_size_w_lt_10</th><th scope=col>obj_size_w_lt_20</th><th scope=col>obj_size_w_lt_50</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Q102248528-30_437_19147411343_2637cb5235_c</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1545.623</td><td>779.7702</td><td>473.9622</td><td>318.652</td><td>431.6084</td><td>216.76</td><td>130.8939</td><td>87.6303</td><td>1.49762</td><td>0.2109995</td><td>0.1197244</td><td>0.01702696</td><td>7</td><td>1.239114</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>6</td><td>7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 31\n",
       "\\begin{tabular}{lllllllllllllllllllllllllllllll}\n",
       " pid & mni\\_k10\\_kick & mni\\_k25\\_kick & mni\\_k50\\_kick & mni\\_k100\\_kick & mni\\_k10\\_kick\\_w & mni\\_k25\\_kick\\_w & mni\\_k50\\_kick\\_w & mni\\_k100\\_kick\\_w & mni\\_k10\\_v3d & mni\\_k25\\_v3d & mni\\_k50\\_v3d & mni\\_k100\\_v3d & mni\\_k10\\_v3d\\_w & mni\\_k25\\_v3d\\_w & mni\\_k50\\_v3d\\_w & mni\\_k100\\_v3d\\_w & freq\\_kick & freq\\_kick\\_w & freq\\_v3d & freq\\_v3d\\_w & obj\\_num & obj\\_num\\_w & obj\\_size\\_lt\\_5 & obj\\_size\\_lt\\_10 & obj\\_size\\_lt\\_20 & obj\\_size\\_lt\\_50 & obj\\_size\\_w\\_lt\\_5 & obj\\_size\\_w\\_lt\\_10 & obj\\_size\\_w\\_lt\\_20 & obj\\_size\\_w\\_lt\\_50\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t Q102248528-30\\_437\\_19147411343\\_2637cb5235\\_c & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1545.623 & 779.7702 & 473.9622 & 318.652 & 431.6084 & 216.76 & 130.8939 & 87.6303 & 1.49762 & 0.2109995 & 0.1197244 & 0.01702696 & 7 & 1.239114 & 0 & 0 & 0 & 0 & 0 & 2 & 6 & 7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 31\n",
       "\n",
       "| pid &lt;chr&gt; | mni_k10_kick &lt;dbl&gt; | mni_k25_kick &lt;dbl&gt; | mni_k50_kick &lt;dbl&gt; | mni_k100_kick &lt;dbl&gt; | mni_k10_kick_w &lt;dbl&gt; | mni_k25_kick_w &lt;dbl&gt; | mni_k50_kick_w &lt;dbl&gt; | mni_k100_kick_w &lt;dbl&gt; | mni_k10_v3d &lt;dbl&gt; | mni_k25_v3d &lt;dbl&gt; | mni_k50_v3d &lt;dbl&gt; | mni_k100_v3d &lt;dbl&gt; | mni_k10_v3d_w &lt;dbl&gt; | mni_k25_v3d_w &lt;dbl&gt; | mni_k50_v3d_w &lt;dbl&gt; | mni_k100_v3d_w &lt;dbl&gt; | freq_kick &lt;dbl&gt; | freq_kick_w &lt;dbl&gt; | freq_v3d &lt;dbl&gt; | freq_v3d_w &lt;dbl&gt; | obj_num &lt;int&gt; | obj_num_w &lt;dbl&gt; | obj_size_lt_5 &lt;int&gt; | obj_size_lt_10 &lt;int&gt; | obj_size_lt_20 &lt;int&gt; | obj_size_lt_50 &lt;int&gt; | obj_size_w_lt_5 &lt;int&gt; | obj_size_w_lt_10 &lt;int&gt; | obj_size_w_lt_20 &lt;int&gt; | obj_size_w_lt_50 &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Q102248528-30_437_19147411343_2637cb5235_c | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1545.623 | 779.7702 | 473.9622 | 318.652 | 431.6084 | 216.76 | 130.8939 | 87.6303 | 1.49762 | 0.2109995 | 0.1197244 | 0.01702696 | 7 | 1.239114 | 0 | 0 | 0 | 0 | 0 | 2 | 6 | 7 |\n",
       "\n"
      ],
      "text/plain": [
       "  pid                                        mni_k10_kick mni_k25_kick\n",
       "1 Q102248528-30_437_19147411343_2637cb5235_c 0            0           \n",
       "  mni_k50_kick mni_k100_kick mni_k10_kick_w mni_k25_kick_w mni_k50_kick_w\n",
       "1 0            0             0              0              0             \n",
       "  mni_k100_kick_w mni_k10_v3d mni_k25_v3d mni_k50_v3d mni_k100_v3d\n",
       "1 0               1545.623    779.7702    473.9622    318.652     \n",
       "  mni_k10_v3d_w mni_k25_v3d_w mni_k50_v3d_w mni_k100_v3d_w freq_kick\n",
       "1 431.6084      216.76        130.8939      87.6303        1.49762  \n",
       "  freq_kick_w freq_v3d  freq_v3d_w obj_num obj_num_w obj_size_lt_5\n",
       "1 0.2109995   0.1197244 0.01702696 7       1.239114  0            \n",
       "  obj_size_lt_10 obj_size_lt_20 obj_size_lt_50 obj_size_w_lt_5 obj_size_w_lt_10\n",
       "1 0              0              0              0               2               \n",
       "  obj_size_w_lt_20 obj_size_w_lt_50\n",
       "1 6                7               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "proj_metrics_p10[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- select 100 from the results ---#\n",
    "\n",
    "proj_metrics_p50 = read_feather('data/v2/proj_metrics_p50_5000v3d.feather') %>% setDT()\n",
    "\n",
    "# select 100 projects, with a fixed random seed\n",
    "set.seed(42)\n",
    "proj_metrics = proj_metrics_p50[\n",
    "    !(pid %in% c('x00001544-000106630', 'n02443484-3_1013_49694581952_73ec646829_c'))\n",
    "    ][sample(.N, 100)]\n",
    "\n",
    "# save the resulting 100 projects to a table\n",
    "write_feather(proj_metrics, 'data/v2/proj_metrics_p50_100v3d.feather')\n",
    "\n",
    "# save the 100 project images to `data/v2/100-sample-v3d-images`\n",
    "# first clear the folder\n",
    "folder_path = \"data/v2/100-sampled-v3d-images/\"\n",
    "file_list <- list.files(folder_path, full.names = TRUE)\n",
    "unlink(file_list)\n",
    "\n",
    "# then copy\n",
    "for (pid in proj_metrics$pid) {\n",
    "    # get the image path\n",
    "    img_path = sprintf('/home/yu/OneDrive/Construal/pretrained-models/v3det/data/V3Det/images/%s/%s.jpg', \n",
    "                       str_split_1(pid, '-')[1], str_split_1(pid, '-')[2])\n",
    "\n",
    "    # copy the image to `data/v2/100-sample-v3d-images`\n",
    "    file.copy(img_path, sprintf('data/v2/100-sampled-v3d-images/%s.jpg', pid))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Ad hoc) Compute the average metrics for the \"full\" V3D dataset\n",
    "\n",
    "The online app needs to compare the image scores with the average level of V3D. Therefore, we need to compute the average V3D score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pyarrow.feather import write_feather, read_feather\n",
    "\n",
    "wdir = '/home/yu/OneDrive/Construal/'\n",
    "os.chdir(wdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Uniqueness\n",
    "\n",
    "Because object-level scores have already been computed, we only need to compute project-level data here.\n",
    "\n",
    "`Naming`: we add the `allv3d` suffix to indicate the metrics are computed for the full V3D images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 106519\n"
     ]
    }
   ],
   "source": [
    "# For V3D, we use 0.5 as the threshold\n",
    "score_threshold = 0.5\n",
    "\n",
    "# load frequency table\n",
    "freq_v3d = read_feather(\n",
    "    # for v3d, we only use one threahold (0.5)\n",
    "    'data/v2/v3det/on-train/freq_p50.feather', \n",
    "    columns=['label', 'freq'])\n",
    "\n",
    "freq = freq_v3d.rename(columns={'freq': 'freq_v3d'}, inplace=False)\n",
    "\n",
    "# load the object detection results\n",
    "obj_det_results = read_feather('data/v2/v3det/on-train/obj_det_results.feather')\n",
    "\n",
    "# we only keep objects with score >= score_threshold\n",
    "obj_det_results = obj_det_results.loc[obj_det_results.score>=score_threshold]\n",
    "\n",
    "# compute the freq of each project\n",
    "# by aggregating the freq of each object in the project\n",
    "proj_freq = (\n",
    "    obj_det_results.merge(freq, on='label', how='inner') \\\n",
    "    .groupby(['pid']) \\\n",
    "    .agg({'freq_v3d': 'mean'}) \\\n",
    "    .rename(columns={'freq_v3d': 'uniqueness'}) \\\n",
    "    .reset_index()\n",
    "    )\n",
    "\n",
    "# print the number of projects left\n",
    "print(f'Number of images: {proj_freq.pid.nunique()}')\n",
    "\n",
    "write_feather(proj_freq, f'data/v2/proj_freq_p{int(score_threshold*100)}_allv3d.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Readability\n",
    "\n",
    "Because object-level scores have already been computed, we only need to compute project-level data here.\n",
    "\n",
    "`Naming`: we add the `allv3d` suffix to indicate the metrics are computed for the full V3D images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 106519\n"
     ]
    }
   ],
   "source": [
    "# for v3d we only use 0.5 as the threshold\n",
    "score_threshold = 0.5\n",
    "\n",
    "# read obj detection results of kickstart projects\n",
    "obj_det_results = read_feather('data/v2/v3det/on-train/obj_det_results.feather')\n",
    "\n",
    "# we only keep the results with score >= score_threshold\n",
    "# and then compute frequency\n",
    "def get_readability(group):\n",
    "    # compute object number\n",
    "    obj_num = len(group)\n",
    "\n",
    "    # compute object size\n",
    "    obj_size_lt_10 = sum(group.size_ratio <= 0.1)\n",
    "\n",
    "    # get gunning fog index\n",
    "    readability = 0.4 * (obj_num + 100 * obj_size_lt_10 / obj_num)\n",
    "\n",
    "    # return\n",
    "    return pd.Series(readability, index=[\"readability\"])\n",
    "\n",
    "readability = (obj_det_results.loc[obj_det_results.score >= score_threshold] \\\n",
    "    .groupby(['pid']) \\\n",
    "    .apply(get_readability) \\\n",
    "    .reset_index())\n",
    "\n",
    "# print number of images\n",
    "print(f'Number of unique images: {readability.pid.nunique()}')\n",
    "\n",
    "# save the readability table\n",
    "write_feather(readability, f'data/v2/proj_read_p{int(score_threshold*100)}_allv3d.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Concreteness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 106519\n"
     ]
    }
   ],
   "source": [
    "# -- load all object-level MNI into one dataset --\n",
    "\n",
    "# load MNI based on V3D (for V3D we only use one threshold, 0.5)\n",
    "obj_mni_k10_v3d = read_feather(\"data/v2/v3det/on-train/obj_mni_k10_p50.feather\")\n",
    "obj_mni_k25_v3d = read_feather(\"data/v2/v3det/on-train/obj_mni_k25_p50.feather\")\n",
    "obj_mni_k50_v3d = read_feather(\"data/v2/v3det/on-train/obj_mni_k50_p50.feather\")\n",
    "obj_mni_k100_v3d = read_feather(\"data/v2/v3det/on-train/obj_mni_k100_p50.feather\")\n",
    "\n",
    "# rename columns in obj_mni_v3d\n",
    "obj_mni_k10_v3d = obj_mni_k10_v3d.rename(columns={\"mni\": \"mni_k10_v3d\"})\n",
    "obj_mni_k25_v3d = obj_mni_k25_v3d.rename(columns={\"mni\": \"mni_k25_v3d\"})\n",
    "obj_mni_k50_v3d = obj_mni_k50_v3d.rename(columns={\"mni\": \"mni_k50_v3d\"})\n",
    "obj_mni_k100_v3d = obj_mni_k100_v3d.rename(columns={\"mni\": \"mni_k100_v3d\"})\n",
    "\n",
    "# merge all MNI datasets\n",
    "obj_mni = (\n",
    "    obj_mni_k10_v3d.merge(obj_mni_k25_v3d, on=\"obj\", how=\"inner\")\n",
    "    .merge(obj_mni_k50_v3d, on=\"obj\", how=\"inner\")\n",
    "    .merge(obj_mni_k100_v3d, on=\"obj\", how=\"inner\")\n",
    ")\n",
    "\n",
    "# for v3d we only use 0.5 as the threshold\n",
    "score_threshold = 0.5\n",
    "\n",
    "# read detection results\n",
    "obj_det_results = read_feather(\n",
    "    'data/v2/v3det/on-train/obj_det_results.feather',\n",
    "    columns=['pid', 'label', 'score'])\n",
    "\n",
    "obj_det_results = obj_det_results.loc[obj_det_results.score>=score_threshold]\n",
    "\n",
    "# compute project-level MNI\n",
    "proj_mni = (\n",
    "    obj_det_results.merge(obj_mni, left_on='label', right_on='obj', how='inner')\n",
    "    .groupby(['pid'])\n",
    "    .agg({'mni_k10_v3d': 'sum'})\n",
    "    .rename(columns={'mni_k10_v3d': 'mni'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# save the project-level MNI\n",
    "write_feather(proj_mni, f'data/v2/proj_mni_p{int(score_threshold*100)}_allv3d.feather')\n",
    "\n",
    "# print the number of unique images\n",
    "print(f\"Number of unique images: {proj_mni.pid.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all(score_threshold):\n",
    "    # Args:\n",
    "    #    score_threshold: the threshold of probability (0.1 or 0.5)\n",
    "\n",
    "    # load mni, frequency, and readability\n",
    "    proj_mni = read_feather(f'data/v2/proj_mni_p{int(score_threshold*100)}_allv3d.feather')\n",
    "    proj_freq = read_feather(f'data/v2/proj_freq_p{int(score_threshold*100)}_allv3d.feather')\n",
    "    proj_read = read_feather(f'data/v2/proj_read_p{int(score_threshold*100)}_allv3d.feather')\n",
    "\n",
    "    # merge them into one\n",
    "    proj_metrics = (\n",
    "        proj_mni.merge(proj_freq, on='pid', how='inner')\n",
    "        .merge(proj_read, on='pid', how='inner')\n",
    "        # .drop(columns=['pid'])\n",
    "        .reset_index()\n",
    "        # .drop(columns=['index'])\n",
    "    )\n",
    "\n",
    "    # print one row\n",
    "    print(proj_metrics)\n",
    "\n",
    "    # return\n",
    "    return proj_metrics\n",
    "\n",
    "proj_metrics_p50 = combine_all(0.5)\n",
    "\n",
    "# save\n",
    "write_feather(proj_metrics_p50, 'data/v2/metrics_dist_p50_allv3d.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniqueness Percentile: 86.5028774209296%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "# proj_metrics_p50 # Compute the percentile of uniqueness\n",
    "\n",
    "uniqueness_percentile = percentileofscore(proj_metrics_p50['uniqueness'], 0.3)\n",
    "\n",
    "# # Compute the percentile of readability\n",
    "# readability_percentile = percentileofscore(proj_metrics_p50['readability'], proj_metrics_p50['readability'])\n",
    "\n",
    "# # Compute the percentile of concreteness\n",
    "# concreteness_percentile = percentileofscore(proj_metrics_p50['concreteness'], proj_metrics_p50['concreteness'])\n",
    "\n",
    "# Print the percentiles\n",
    "print(f\"Uniqueness Percentile: {uniqueness_percentile}%\")\n",
    "# print(f\"Readability Percentile: {readability_percentile}%\")\n",
    "# print(f\"Concreteness Percentile: {concreteness_percentile}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.5028774209296"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueness_percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Ad hoc) Combine machine and survey results\n",
    "\n",
    "For the 100 sampled V3D images:\n",
    "- Machine results: computed by myself\n",
    "- Survey results: from Amrita\n",
    "\n",
    "We merge these two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 35)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "wdir = '/home/yu/OneDrive/Construal'\n",
    "os.chdir(wdir)\n",
    "\n",
    "# read machine table\n",
    "machine = pd.read_feather('/home/yu/OneDrive/Construal/data/v2/proj_metrics_p50_100v3d.feather')\n",
    "machine = machine.rename(columns=str.lower)\n",
    "\n",
    "# read survey table\n",
    "survey = pd.read_excel('/home/yu/OneDrive/Construal/data/v2/survey-results/V3D.xlsx')\n",
    "survey = survey.rename(columns=str.lower)\n",
    "survey['pid'] = survey.pid.str.split('.').str[0]\n",
    "\n",
    "# combine the two\n",
    "combined = machine.merge(survey, on='pid', how='inner')\n",
    "combined.shape\n",
    "combined.to_feather('data/v2/survey-results/machine-survey-combined.feather')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
