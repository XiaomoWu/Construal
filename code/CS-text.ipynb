{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Concreteness (R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `dfm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(spacyr)\n",
    "library(quanteda)\n",
    "\n",
    "spacy_initialize(model='en_core_web_lg',\n",
    "                 save_profile = T)\n",
    "\n",
    "ld(pjson, ldtype='feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create corpus\n",
    "corpus = pjson[, .(pid, project_desc)] %>%\n",
    "    corpus(docid_field='pid', text_field='project_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize with spacy\n",
    "# the results is a data.frame\n",
    "# 1) keep both \"raw\" and \"lemma\" tokens \n",
    "# 2) tokens are case-sensitive\n",
    "tokens_as_df = corpus %>%\n",
    "    spacy_parse(pos=F, entity=F)\n",
    "\n",
    "sv(tokens_as_df)\n",
    "sv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokens consisting of 1 document.\n",
       "1000064918 :\n",
       " [1] \"the\"     \"Beard\"   \"be\"      \"a\"       \"comedy\"  \"base\"    \"comic\"  \n",
       " [8] \"about\"   \"an\"      \"average\" \"guy\"     \"that\"   \n",
       "[ ... and 108 more ]\n",
       "-tokens_lemmatized- saved  (10.24 secs)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert `tokens_as_df` to quanteda `tokens` object\n",
    "# 1) we use the lemmatized tokens, because the lookup table is also lemmatized \n",
    "# 2) tokens are case-sensitive\n",
    "tokens_as_qeda = tokens_as_df %>%\n",
    "    as.tokens(use_lemma=T)\n",
    "\n",
    "tokens_as_qeda[1]\n",
    "\n",
    "sv(tokens_as_qeda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of tokens of each doc\n",
    "ntoken_corpus = ntoken(tokens_as_qeda)\n",
    "ntoken_corpus = data.table(pid=names(ntoken_corpus), ntoken=ntoken_corpus)\n",
    "ntoken_corpus[1]\n",
    "sv(ntoken_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_as_qeda (47.5 MB) already loaded, will NOT load again! (0 secs) (2021-03-07 5:55 PM)\n",
      "\"cs_dfm_first200\" saved as \"cs_dfm_first200.rds\" (43.1 MB) (7.55 secs, 2021-03-07 17:56:10)\n"
     ]
    }
   ],
   "source": [
    "# Convert tokens to dfm\n",
    "ld(tokens_as_qeda, force=T)\n",
    "\n",
    "tokens_to_dfm <- function(tokens_as_qeda, startpos=1, endpos=-1) {\n",
    "    # select tokens\n",
    "    tokens = tokens_select(tokens_as_qeda, startpos=startpos, endpos=endpos)\n",
    "    \n",
    "    # create ngram\n",
    "    tokens_ngram = tokens %>%\n",
    "        tokens_ngrams(n=1:2, concatenator = \" \")\n",
    "    \n",
    "    # create dfm\n",
    "    cs_dfm = tokens_ngram %>% dfm(tolower=T, stem=F)\n",
    "}\n",
    "\n",
    "cs_dfm = tokens_to_dfm(tokens_as_qeda)\n",
    "cs_dfm_first200 = tokens_to_dfm(tokens_as_qeda, endpos=200)\n",
    "\n",
    "# sv(cs_dfm)\n",
    "sv(cs_dfm_first200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute B-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"df\" saved as \"nltk_stopwords.feather\" (2.5 KB) (<1s)\n"
     ]
    }
   ],
   "source": [
    "# get stopwords from nltk (Python code)\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "df = pd.DataFrame({'word':list(stopwords)})\n",
    "sv('df', svname='nltk_stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"nltk_stopwords.feather\" (2.5 KB) loaded (0.02 secs) (2021-05-06 8:37 AM)\n",
      "0.310356910447018% words are stopwords"
     ]
    }
   ],
   "source": [
    "# ------------ Create bscore dict ----------------\n",
    "# load stop word list\n",
    "ld(nltk_stopwords, force=T)\n",
    "nltk_stopwords = nltk_stopwords[,word]\n",
    "\n",
    "# read raw bscore\n",
    "bscore_dt = fread('/home/yu/OneDrive/Construal/data/concreteness score.csv')[, .(word=str_trim(Word), score=Conc.M)]\n",
    "\n",
    "# create TWO bscore, one has stopwords, one doesn't \n",
    "bscore = bscore_dt$score\n",
    "names(bscore) = bscore_dt$word\n",
    "\n",
    "bscore_nostopwords = bscore[!(names(bscore)%in%nltk_stopwords)]\n",
    "\n",
    "sprintf('%s%% words are stopwords', (1-length(bscore_nostopwords)/length(bscore))*100%>%round(2)) %>% cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntoken_corpus (282.9 KB) already loaded, will NOT load again! (0 secs) (2021-05-06 9:34 AM)\n",
      "\"cs_dfm.rds\" (116.8 MB) loaded (3.99 secs) (2021-05-06 9:34 AM)\n",
      "\"cs_dfm_first200.rds\" (43.1 MB) loaded (1.71 secs) (2021-05-06 9:34 AM)\n",
      "\"bscore_nostopwords.rds\" (232.4 KB) loaded (0.03 secs) (2021-05-06 9:34 AM)\n"
     ]
    }
   ],
   "source": [
    "# ------------ Create bscore from dtm ----------------\n",
    "\n",
    "ld(ntoken_corpus)\n",
    "ld(cs_dfm, force=T)\n",
    "ld(cs_dfm_first200, force=T)\n",
    "ld(bscore_nostopwords, force=T)\n",
    "\n",
    "\n",
    "dfm_to_bscore <- function(cs_dfm, bscore_dict, type_name='') {\n",
    "    ntoken_name = str_c('ntoken_bscore', type_name)\n",
    "    ntoken_unique_name = str_c('ntoken_unique', type_name)\n",
    "    ntoken_bscore_unique_name = str_c('ntoken_bscore_unique', type_name)\n",
    "    bscore_name = str_c('bscore', type_name)\n",
    "    \n",
    "    output_name = c('pid', bscore_name)\n",
    "\n",
    "    ntoken_unique = ntype(cs_dfm)\n",
    "\n",
    "    dfm_bscore = dfm_match(cs_dfm, names(bscore_dict))\n",
    "    ntoken_bscore = ntoken(dfm_bscore)\n",
    "    ntoken_bscore_unique = ntype(dfm_bscore) \n",
    "    ntoken_bscore_dt = data.table(pid=names(ntoken_bscore))\n",
    "    ntoken_bscore_dt = ntoken_bscore_dt[, (ntoken_name) := ntoken_bscore\n",
    "        ][, (ntoken_unique_name) := ntoken_unique\n",
    "        ][, (ntoken_bscore_unique_name) := ntoken_bscore_unique]\n",
    "    \n",
    "    \n",
    "    dfm_bscore_weighted = dfm_weight(dfm_bscore, weights=bscore_dict)\n",
    "    dfm_bscore_weighted = convert(dfm_bscore_weighted, 'data.frame',\n",
    "                                  docid_field='pid'\n",
    "                                 ) %>% as.data.table()\n",
    "    \n",
    "    bscore_by_pid = dfm_bscore_weighted[, (bscore_name) := rowSums(.SD),\n",
    "                                        .SDcols=is.numeric\n",
    "        ][, ..output_name]\n",
    "    \n",
    "    bscore = bscore_by_pid[ntoken_bscore_dt, on=.(pid)]\n",
    "}\n",
    "\n",
    "bscore_bypid = dfm_to_bscore(cs_dfm, bscore)\n",
    "# bscore_bypid_nostopwords = dfm_to_bscore(cs_dfm, bscore_nostopwords, \n",
    "#                                          type_name='_nostopwords')\n",
    "# bscore_bypid_firstn = dfm_to_bscore(cs_dfm_first200, bscore,\n",
    "#                                     type_name='_first200')\n",
    "# bscore_bypid_firstn_nostopwords = dfm_to_bscore(cs_dfm_first200,\n",
    "#                                                 bscore_nostopwords,\n",
    "#                                                 type_name='_first200_nostopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwrite(bscore_bypid_final, '../data/bscore_bypid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"bscore_bypid_final\" saved as \"bscore_bypid.feather\" (2.4 MB) (0.01 secs, 2021-05-06 09:35:38)\n"
     ]
    }
   ],
   "source": [
    "bscore_bypid_final = bscore_bypid[bscore_bypid_nostopwords, on=.(pid)\n",
    "    ][bscore_bypid_firstn, on=.(pid)\n",
    "    ][bscore_bypid_firstn_nostopwords, on=.(pid)\n",
    "    ][ntoken_corpus, on=.(pid)]\n",
    "\n",
    "sv(bscore_bypid_final, 'bscore_bypid')\n",
    "fwrite(bscore_bypid_final, '../data/bscore_bypid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'pid'</li><li>'bscore'</li><li>'ntoken_bscore'</li><li>'ntoken_unique'</li><li>'ntoken_bscore_unique'</li><li>'bscore_nostopwords'</li><li>'ntoken_bscore_nostopwords'</li><li>'ntoken_unique_nostopwords'</li><li>'ntoken_bscore_unique_nostopwords'</li><li>'bscore_first200'</li><li>'ntoken_bscore_first200'</li><li>'ntoken_unique_first200'</li><li>'ntoken_bscore_unique_first200'</li><li>'bscore_first200_nostopwords'</li><li>'ntoken_bscore_first200_nostopwords'</li><li>'ntoken_unique_first200_nostopwords'</li><li>'ntoken_bscore_unique_first200_nostopwords'</li><li>'ntoken'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'pid'\n",
       "\\item 'bscore'\n",
       "\\item 'ntoken\\_bscore'\n",
       "\\item 'ntoken\\_unique'\n",
       "\\item 'ntoken\\_bscore\\_unique'\n",
       "\\item 'bscore\\_nostopwords'\n",
       "\\item 'ntoken\\_bscore\\_nostopwords'\n",
       "\\item 'ntoken\\_unique\\_nostopwords'\n",
       "\\item 'ntoken\\_bscore\\_unique\\_nostopwords'\n",
       "\\item 'bscore\\_first200'\n",
       "\\item 'ntoken\\_bscore\\_first200'\n",
       "\\item 'ntoken\\_unique\\_first200'\n",
       "\\item 'ntoken\\_bscore\\_unique\\_first200'\n",
       "\\item 'bscore\\_first200\\_nostopwords'\n",
       "\\item 'ntoken\\_bscore\\_first200\\_nostopwords'\n",
       "\\item 'ntoken\\_unique\\_first200\\_nostopwords'\n",
       "\\item 'ntoken\\_bscore\\_unique\\_first200\\_nostopwords'\n",
       "\\item 'ntoken'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'pid'\n",
       "2. 'bscore'\n",
       "3. 'ntoken_bscore'\n",
       "4. 'ntoken_unique'\n",
       "5. 'ntoken_bscore_unique'\n",
       "6. 'bscore_nostopwords'\n",
       "7. 'ntoken_bscore_nostopwords'\n",
       "8. 'ntoken_unique_nostopwords'\n",
       "9. 'ntoken_bscore_unique_nostopwords'\n",
       "10. 'bscore_first200'\n",
       "11. 'ntoken_bscore_first200'\n",
       "12. 'ntoken_unique_first200'\n",
       "13. 'ntoken_bscore_unique_first200'\n",
       "14. 'bscore_first200_nostopwords'\n",
       "15. 'ntoken_bscore_first200_nostopwords'\n",
       "16. 'ntoken_unique_first200_nostopwords'\n",
       "17. 'ntoken_bscore_unique_first200_nostopwords'\n",
       "18. 'ntoken'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"pid\"                                      \n",
       " [2] \"bscore\"                                   \n",
       " [3] \"ntoken_bscore\"                            \n",
       " [4] \"ntoken_unique\"                            \n",
       " [5] \"ntoken_bscore_unique\"                     \n",
       " [6] \"bscore_nostopwords\"                       \n",
       " [7] \"ntoken_bscore_nostopwords\"                \n",
       " [8] \"ntoken_unique_nostopwords\"                \n",
       " [9] \"ntoken_bscore_unique_nostopwords\"         \n",
       "[10] \"bscore_first200\"                          \n",
       "[11] \"ntoken_bscore_first200\"                   \n",
       "[12] \"ntoken_unique_first200\"                   \n",
       "[13] \"ntoken_bscore_unique_first200\"            \n",
       "[14] \"bscore_first200_nostopwords\"              \n",
       "[15] \"ntoken_bscore_first200_nostopwords\"       \n",
       "[16] \"ntoken_unique_first200_nostopwords\"       \n",
       "[17] \"ntoken_bscore_unique_first200_nostopwords\"\n",
       "[18] \"ntoken\"                                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bscore_bypid_final %>% names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Freq (R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the word frequency from the Google dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_as_df (462.3 MB) already loaded, will NOT load again! (0 secs) (2021-04-06 7:35 PM)\n",
      "nltk_stopwords (2.5 KB) already loaded, will NOT load again! (0 secs) (2021-04-06 7:35 PM)\n"
     ]
    }
   ],
   "source": [
    "ld(tokens_as_df)\n",
    "ld(nltk_stopwords)\n",
    "\n",
    "google_freqdict_withstop = fread('data/freqdict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 2 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>word</th><th scope=col>freq_google_withoutstop</th><th scope=col>freq_google_withstop</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>the</td><td>NA</td><td>1.0000000</td></tr>\n",
       "\t<tr><td>of </td><td>NA</td><td>0.5684659</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 2 × 3\n",
       "\\begin{tabular}{lll}\n",
       " word & freq\\_google\\_withoutstop & freq\\_google\\_withstop\\\\\n",
       " <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t the & NA & 1.0000000\\\\\n",
       "\t of  & NA & 0.5684659\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 2 × 3\n",
       "\n",
       "| word &lt;chr&gt; | freq_google_withoutstop &lt;dbl&gt; | freq_google_withstop &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| the | NA | 1.0000000 |\n",
       "| of  | NA | 0.5684659 |\n",
       "\n"
      ],
      "text/plain": [
       "  word freq_google_withoutstop freq_google_withstop\n",
       "1 the  NA                      1.0000000           \n",
       "2 of   NA                      0.5684659           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "google_freqdict = google_freqdict_withstop[\n",
    "      !(word %in% nltk_stopwords$word),\n",
    "    ][, .(word, freq_google_withoutstop=freq/max(freq))\n",
    "    ][google_freqdict_withstop[, .(word, freq_google_withstop=freq)], \n",
    "      on=.(word)\n",
    "    # ][, ':='(freq_google_withoutstop=nafill(freq_google_withoutstop, 'const', 0))\n",
    "    ][order(-freq_google_withstop)]\n",
    "\n",
    "google_freqdict[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"google_freqdict\" saved as \"google_freqdict.feather\" (1.2 MB) (0.01 secs, 2021-04-06 23:43:00)\n"
     ]
    }
   ],
   "source": [
    "sv(google_freqdict)\n",
    "fwrite(google_freqdict, 'data/Sharing/google_freqdict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the word frequency from the Kickstarer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = c(',', '.', '-', '?', '!', '(', ')', '$', '/', ':', ' ', '\"', intToUtf8(160))\n",
    "\n",
    "kck_freqdict_withstopwords = tokens_as_df[, .(doc_id, word=tolower(token))\n",
    "    ][!(word %in% punct)\n",
    "    ][, .(n=.N), keyby=.(word)\n",
    "    ][, ':='(freq_kck_withstop=n/max(n))\n",
    "    ][order(-freq_kck_withstop), .(word, freq_kck_withstop)]\n",
    "\n",
    "kck_freqdict_withoutstopwords = tokens_as_df[, .(doc_id, word=tolower(token))\n",
    "    ][(!(word %in% punct)) & (!(word %in% nltk_stopwords$word))\n",
    "    ][, .(n=.N), keyby=.(word)\n",
    "    ][, ':='(freq_kck_withoutstop=n/max(n))\n",
    "    ][order(-freq_kck_withoutstop), .(word, freq_kck_withoutstop)]\n",
    "\n",
    "fwrite(kck_freqdict_withstopwords, 'data/Sharing/kck_freqdict_withstopwords.csv')\n",
    "fwrite(kck_freqdict_withoutstopwords, 'data/Sharing/kck_freqdict_withoutstopwords.csv')\n",
    "\n",
    "kck_freqdict = kck_freqdict_withoutstopwords[kck_freqdict_withstopwords, on=.(word)\n",
    "    # ][, ':='(freq_kck_withoutstop=nafill(freq_kck_withoutstop, 'const', 0))\n",
    "    ][order(-freq_kck_withstop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld(kck_freqdict)\n",
    "kck_freqdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwrite(kck_freqdict, '../data/word_freq_kick.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"kck_freqdict\" saved as \"kck_freqdict.feather\" (9 MB) (0.35 secs, 2021-04-06 23:38:29)\n"
     ]
    }
   ],
   "source": [
    "sv(kck_freqdict)\n",
    "fwrite(kck_freqdict, 'data/Sharing/kck_freqdict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kck_freqdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Kickstar_freq with Google_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"freq_dict\" saved as \"freq_dict.feather\" (9.8 MB) (0.35 secs, 2021-04-06 20:09:14)\n"
     ]
    }
   ],
   "source": [
    "freq_dict = google_freqdict[kck_freqdict, on=.(word)]\n",
    "freq_dict = freq_dict[order(-freq_google_withstop)\n",
    "    ][, ':='(\n",
    "      top_google_withoutstop=word %in% word[!is.na(freq_google_withoutstop)][1:5000],\n",
    "      top_google_withstop=word %in% word[!is.na(freq_google_withstop)][1:5000]\n",
    "      )\n",
    "    ][order(-freq_kck_withstop)\n",
    "    ][, ':='(\n",
    "      top_kck_withoutstop=word %in% word[!is.na(freq_kck_withoutstop)][1:5000],\n",
    "      top_kck_withstop=word %in% word[!is.na(freq_kck_withstop)][1:5000]\n",
    "      )]\n",
    "      \n",
    "sv(freq_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the \"frequency score\"\n",
    "\n",
    "- top 5000 words or all\n",
    "- with/without stopwords\n",
    "- based on kickstarter or LVIS\n",
    "\n",
    "So there're 2 * 2 * 2=8 versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"freq_dict.feather\" (9.8 MB) loaded (0.19 secs) (2021-04-06 8:09 PM)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>word</th><th scope=col>freq_google_withoutstop</th><th scope=col>freq_google_withstop</th><th scope=col>freq_kck_withoutstop</th><th scope=col>freq_kck_withstop</th><th scope=col>top_google_withoutstop</th><th scope=col>top_google_withstop</th><th scope=col>top_kck_withoutstop</th><th scope=col>top_kck_withstop</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;lgl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>the</td><td>NA</td><td>1</td><td>NA</td><td>1</td><td>FALSE</td><td>TRUE</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " word & freq\\_google\\_withoutstop & freq\\_google\\_withstop & freq\\_kck\\_withoutstop & freq\\_kck\\_withstop & top\\_google\\_withoutstop & top\\_google\\_withstop & top\\_kck\\_withoutstop & top\\_kck\\_withstop\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <lgl> & <lgl> & <lgl> & <lgl>\\\\\n",
       "\\hline\n",
       "\t the & NA & 1 & NA & 1 & FALSE & TRUE & FALSE & TRUE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 9\n",
       "\n",
       "| word &lt;chr&gt; | freq_google_withoutstop &lt;dbl&gt; | freq_google_withstop &lt;dbl&gt; | freq_kck_withoutstop &lt;dbl&gt; | freq_kck_withstop &lt;dbl&gt; | top_google_withoutstop &lt;lgl&gt; | top_google_withstop &lt;lgl&gt; | top_kck_withoutstop &lt;lgl&gt; | top_kck_withstop &lt;lgl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| the | NA | 1 | NA | 1 | FALSE | TRUE | FALSE | TRUE |\n",
       "\n"
      ],
      "text/plain": [
       "  word freq_google_withoutstop freq_google_withstop freq_kck_withoutstop\n",
       "1 the  NA                      1                    NA                  \n",
       "  freq_kck_withstop top_google_withoutstop top_google_withstop\n",
       "1 1                 FALSE                  TRUE               \n",
       "  top_kck_withoutstop top_kck_withstop\n",
       "1 FALSE               TRUE            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ld(freq_dict, force=T)\n",
    "freq_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = c(',', '.', '-', '?', '!', '(', ')', '$', '/', ':', ' ', '\"', intToUtf8(160))\n",
    "\n",
    "score = tokens_as_df[,.(doc_id, word=tolower(token))\n",
    "    ][!(word %in% punct)\n",
    "    ][freq_dict, \n",
    "      on=.(word), nomatch=NULL\n",
    "    ][, .(score_google_all_withstop=sum(freq_google_withstop, na.rm=T),\n",
    "          score_google_all_withoutstop=sum(freq_google_withoutstop, na.rm=T),\n",
    "          score_google_top5000_withstop=sum(freq_google_withstop[top_google_withstop], na.rm=T),\n",
    "          score_google_top5000_withoutstop=sum(freq_google_withoutstop[top_google_withstop], na.rm=T),\n",
    "          score_kck_all_withstop=sum(freq_kck_withstop, na.rm=T),\n",
    "          score_kck_all_withoutstop=sum(freq_kck_withoutstop, na.rm=T),\n",
    "          score_kck_top5000_withstop=sum(freq_kck_withstop[top_google_withstop], na.rm=T),\n",
    "          score_kck_top5000_withoutstop=sum(freq_kck_withoutstop[top_google_withstop], na.rm=T),\n",
    "          n_words_withstop=.N,\n",
    "          n_words_withoutstop=sum(!(word%in%(nltk_stopwords$word)))\n",
    "        ),\n",
    "      keyby=.(doc_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"score\" saved as \"score.feather\" (3.3 MB) (0.01 secs, 2021-04-06 23:32:40)\n"
     ]
    }
   ],
   "source": [
    "sv(score)\n",
    "fwrite(score, 'data/Sharing/text_freq_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"score.feather\" (3.3 MB) loaded (0.04 secs) (2021-05-06 8:05 AM)\n"
     ]
    }
   ],
   "source": [
    "ld(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'doc_id'</li><li>'score_google_all_withstop'</li><li>'score_google_all_withoutstop'</li><li>'score_google_top5000_withstop'</li><li>'score_google_top5000_withoutstop'</li><li>'score_kck_all_withstop'</li><li>'score_kck_all_withoutstop'</li><li>'score_kck_top5000_withstop'</li><li>'score_kck_top5000_withoutstop'</li><li>'n_words_withstop'</li><li>'n_words_withoutstop'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'doc\\_id'\n",
       "\\item 'score\\_google\\_all\\_withstop'\n",
       "\\item 'score\\_google\\_all\\_withoutstop'\n",
       "\\item 'score\\_google\\_top5000\\_withstop'\n",
       "\\item 'score\\_google\\_top5000\\_withoutstop'\n",
       "\\item 'score\\_kck\\_all\\_withstop'\n",
       "\\item 'score\\_kck\\_all\\_withoutstop'\n",
       "\\item 'score\\_kck\\_top5000\\_withstop'\n",
       "\\item 'score\\_kck\\_top5000\\_withoutstop'\n",
       "\\item 'n\\_words\\_withstop'\n",
       "\\item 'n\\_words\\_withoutstop'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'doc_id'\n",
       "2. 'score_google_all_withstop'\n",
       "3. 'score_google_all_withoutstop'\n",
       "4. 'score_google_top5000_withstop'\n",
       "5. 'score_google_top5000_withoutstop'\n",
       "6. 'score_kck_all_withstop'\n",
       "7. 'score_kck_all_withoutstop'\n",
       "8. 'score_kck_top5000_withstop'\n",
       "9. 'score_kck_top5000_withoutstop'\n",
       "10. 'n_words_withstop'\n",
       "11. 'n_words_withoutstop'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"doc_id\"                           \"score_google_all_withstop\"       \n",
       " [3] \"score_google_all_withoutstop\"     \"score_google_top5000_withstop\"   \n",
       " [5] \"score_google_top5000_withoutstop\" \"score_kck_all_withstop\"          \n",
       " [7] \"score_kck_all_withoutstop\"        \"score_kck_top5000_withstop\"      \n",
       " [9] \"score_kck_top5000_withoutstop\"    \"n_words_withstop\"                \n",
       "[11] \"n_words_withoutstop\"             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score %>% names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 4.0.5",
   "language": "R",
   "name": "ir403"
  },
  "language_info": {
   "name": "R",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}