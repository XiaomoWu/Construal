{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you've not installed my toolbox `utilr`, please install through:\n",
    "# devtools::install_github('xiaomowu/utilr')\n",
    "# then `library(utilr)`q\n",
    "library(utilr)\n",
    "library(jsonlite)\n",
    "library(quanteda)\n",
    "\n",
    "quanteda_options(threads = 32) # On your laptop, you probably want to set it to 4 or 8.\n",
    "\n",
    "setwd('~/OneDrive/Construal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get `project_ids` and `project_dirs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = './data/Kickstarter Data/'\n",
    "\n",
    "project_ids = list.dirs(data_root_dir, full.names=F, recursive=F)\n",
    "\n",
    "project_dirs = str_c(data_root_dir, project_ids, '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pjson = vector(mode = \"list\", length=length(project_ids))\n",
    "\n",
    "for (i in 1:length(project_ids)) {\n",
    "    pid = project_ids[i]\n",
    "    pdir = project_dirs[i]\n",
    "    \n",
    "    tryCatch({\n",
    "        json_path = sprintf('%s/%s.json', pdir, pid)\n",
    "        json = fromJSON(json_path)\n",
    "        json$pledge_money = str_c(json$pledge_money, collapse=',')\n",
    "        json$pledge_count = str_c(json$pledge_count, collapse=',')\n",
    "        pjson[[pid]] = json\n",
    "    }, error=function(cond) {\n",
    "        message(sprintf('Error: %s', json_path))\n",
    "        NULL\n",
    "    })\n",
    "}\n",
    "\n",
    "pjson = rbindlist(pjson, use.names=T, idcol='pid') %>% unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_feather(pjson, './data/pjson.feather', version = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99.97% projects have been successfully parsed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "success_pct = round(pjson[, .N]/length(project_ids)*100, 2)\n",
    "message(sprintf('%s%% projects have been successfully parsed.', success_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.table: 1 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>pid</th><th scope=col>pledge_count</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1000064918</td><td>0,0,9,2,4,0,0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 2\n",
       "\\begin{tabular}{ll}\n",
       " pid & pledge\\_count\\\\\n",
       " <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t 1000064918 & 0,0,9,2,4,0,0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 2\n",
       "\n",
       "| pid &lt;chr&gt; | pledge_count &lt;chr&gt; |\n",
       "|---|---|\n",
       "| 1000064918 | 0,0,9,2,4,0,0 |\n",
       "\n"
      ],
      "text/plain": [
       "  pid        pledge_count \n",
       "1 1000064918 0,0,9,2,4,0,0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pjson[1, .(pid, pledge_count)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# Parse HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get `project_ids` and `project_dirs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = './data/Kickstarter Data/'\n",
    "\n",
    "project_ids = list.dirs(data_root_dir, full.names=F, recursive=F)\n",
    "\n",
    "project_dirs = str_c(data_root_dir, project_ids, '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk\n",
    "# the json file already captured the risk portion\n",
    "risk = getNodeSet(parsed_html, '//div[@class=\"mb3 mb10-sm mb3 js-risks\"]//p') %>%\n",
    "    xmlValue() %>%\n",
    "    str_c(collapse='\\n')\n",
    "\n",
    "# cat(sprintf('[risk]:\\n%s\\n', risk))\n",
    "# cat('---------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"enamel pin product specs:\" \"about us:\"                \n",
      "[3] \"shipping:\"                \n"
     ]
    }
   ],
   "source": [
    "# get parsed_html\n",
    "pid = 1649873594\n",
    "html_page = sprintf(\"C:/Users/rossz/OneDrive/Construal/data/Kickstarter Data/%s/%s.html\", pid, pid)\n",
    "parsed_html = htmlParse(html_page)\n",
    "\n",
    "\n",
    "split_team_and_project <- function(pid,\n",
    "    parsed_html, \n",
    "    bold_title_xpath,\n",
    "    pos_team_xpath) {\n",
    "    \n",
    "    # possible team_titles\n",
    "    team_titles = c(\"Who's on the team?\", \"The Team\", \"About Us\", \"About the Artist\", \"Meet the team\", \"Who we are\", \"Meet the creators\", \n",
    "                    \"Who's involved\", \"Who is involved\") %>% tolower()\n",
    "    \n",
    "    # root node for proj_desc and team_desc\n",
    "    root = xmlDoc(parsed_html['//div[@class=\"full-description js-full-description responsive-media formatted-lists\"]'][[1]])\n",
    "    \n",
    "    # all the <p> under the root\n",
    "    all_p = root['//p']\n",
    "    \n",
    "    # set default team_desc/proj_desc\n",
    "    team_desc = NA\n",
    "    proj_desc = getNodeSet(parsed_html, '//div[@class=\"full-description js-full-description responsive-media formatted-lists\"]//text()') %>%\n",
    "        xmlValue() %>%\n",
    "        str_c(collapse='\\n') %>%\n",
    "        str_trim()\n",
    "    success_counter = 0\n",
    "    \n",
    "    # print(proj_desc)\n",
    "    \n",
    "    # find out all bold titles\n",
    "    # convert them to lower case\n",
    "    bold_titles = getNodeSet(root, bold_title_xpath) %>%\n",
    "        xmlValue() %>%\n",
    "        str_trim() %>%\n",
    "        tolower()\n",
    "    \n",
    "    # print(bold_titles)\n",
    "    \n",
    "    # loop over every possible team_title\n",
    "    for (team_title in team_titles) {\n",
    "        idx = match(team_title, bold_titles)\n",
    "        \n",
    "        # if successfully finds team_title, output BOTH team_description and project_descriptoin;\n",
    "        # else, pased_html as project_description\n",
    "        if (is.na(idx)) {\n",
    "            next\n",
    "        } else {\n",
    "            success_counter = success_counter + 1\n",
    "            \n",
    "            team_title_next = bold_titles[idx+1]\n",
    "            \n",
    "#             print(team_title)\n",
    "#             print(team_title_next)\n",
    "            \n",
    "            \n",
    "           \n",
    "            pos_team_start = getNodeSet(all_p, sprintf(pos_team_xpath, team_title))\n",
    "\n",
    "            pos_team_end = getNodeSet(all_p, sprintf(pos_team_xpath, team_title_next))\n",
    "\n",
    "            # extract team_description\n",
    "            team_desc = getNodeSet(all_p, sprintf('//p[position()>%s and position()<%s]', pos_team_start, pos_team_end)) %>%\n",
    "                xmlValue() %>%\n",
    "                str_c(collapse='\\n') %>%  \n",
    "                str_trim()\n",
    "            \n",
    "#             print(pos_team_start)\n",
    "#             print(pos_team_end)\n",
    "            \n",
    "\n",
    "            \n",
    "            # extract project_description\n",
    "            proj_desc = getNodeSet(all_p, sprintf('//p[position()<=%s or position()>=%s]', pos_team_start, pos_team_end)) %>%\n",
    "                xmlValue() %>%\n",
    "                str_c(collapse='\\n') %>%\n",
    "                str_trim()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # log message if more than one team_description have been found\n",
    "    if (success_counter>1) {\n",
    "        message(sprintf('More than one team_description have been found (%s).', parsed_html))\n",
    "    }\n",
    "    return(list(pid=pid, team_desc=team_desc, proj_desc=proj_desc))\n",
    "}\n",
    "\n",
    "# h1 = split_team_and_project(\n",
    "#     pid,\n",
    "#     parsed_html,\n",
    "#     bold_title_xpath='//div[@class=\"full-description js-full-description responsive-media formatted-lists\"]//h1',\n",
    "#     pos_team_xpath='count(//div[@class=\"full-description js-full-description responsive-media formatted-lists\"]//h1[contains(lower-case(text()),\"%s\")]/preceding-sibling::p)+1')\n",
    "# print(h1)\n",
    "\n",
    "b = split_team_and_project(\n",
    "    pid,\n",
    "    parsed_html,\n",
    "    bold_title_xpath='//p[count(./b)=1]//b',\n",
    "    pos_team_xpath='count(//p[contains(lower-case(text()),\"%s\")]/preceding-sibling::p)+1')\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Floral Tiger is part of our Floral Endangered Animals pin series, featuring these majestic cats! Choose between Orange Bengal or White Tiger, or both!</p> "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Classes 'XMLInternalElementNode', 'XMLInternalNode', 'XMLAbstractNode' <externalptr> \n"
     ]
    }
   ],
   "source": [
    "all_p[[1]]\n",
    "cat('---------')\n",
    "str(all_p[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get parsed_html\n",
    "pid = 1649873594\n",
    "html_page = sprintf(\"C:/Users/rossz/OneDrive/Construal/data/Kickstarter Data/%s/%s.html\", pid, pid)\n",
    "parsed_html = htmlParse(html_page)\n",
    "\n",
    "root = parsed_html['//div[@class=\"full-description js-full-description responsive-media formatted-lists\"]'][[1]]\n",
    "\n",
    "root_children = xmlChildren(root) # I shouldn't use `xmlChildren` \n",
    "length(root_children)\n",
    "\n",
    "# root_children[[2]] %>% class()\n",
    "# root_children[[2]]\n",
    "cat('------------\\n')\n",
    "\n",
    "getNodeSet(root, './/p[count(.//b)=1 and contains(.//b, \"About\")]/preceding::*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = xmlDoc(parsed_html['//div[@class=\"full-description js-full-description responsive-media formatted-lists\"]'][[1]])\n",
    "\n",
    "pos_team_start = getNodeSet(root, sprintf('count(//p[contains(lower-case(.//b/text()),\"%s\")]/preceding-sibling::*)+1', 'about'))\n",
    "pos_team_start\n",
    "\n",
    "names(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'XMLInternalElementNode'</li><li>'XMLInternalNode'</li><li>'XMLAbstractNode'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'XMLInternalElementNode'\n",
       "\\item 'XMLInternalNode'\n",
       "\\item 'XMLAbstractNode'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'XMLInternalElementNode'\n",
       "2. 'XMLInternalNode'\n",
       "3. 'XMLAbstractNode'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"XMLInternalElementNode\" \"XMLInternalNode\"        \"XMLAbstractNode\"       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class(parsed_html['//div[@class=\"full-description js-full-description responsive-media formatted-lists\"]'][1][[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_p = getNodeSet(parsed_html, '//div[@class=\"full-description js-full-description responsive-media formatted-lists\"]//p')\n",
    "\n",
    "getNodeSet(all_p[[1]], './/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getNodeSet(parsed_html, \n",
    "           sprintf('//div[@class=\"full-description js-full-description responsive-media formatted-lists\"]//p[contains(lower-case(./b/text()),\"%s\")]', 'shipping'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Concreteness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `dfm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(spacyr)\n",
    "library(quanteda)\n",
    "\n",
    "spacy_initialize(model='en_core_web_lg',\n",
    "                 save_profile = T)\n",
    "\n",
    "ld(pjson, ldtype='feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create corpus\n",
    "corpus = pjson[, .(pid, project_desc)] %>%\n",
    "    corpus(docid_field='pid', text_field='project_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize with spacy\n",
    "# the results is a data.frame\n",
    "# 1) keep both \"raw\" and \"lemma\" tokens \n",
    "# 2) tokens are case-sensitive\n",
    "tokens_as_df = corpus %>%\n",
    "    spacy_parse(pos=F, entity=F)\n",
    "\n",
    "sv(tokens_as_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokens consisting of 1 document.\n",
       "1000064918 :\n",
       " [1] \"the\"     \"Beard\"   \"be\"      \"a\"       \"comedy\"  \"base\"    \"comic\"  \n",
       " [8] \"about\"   \"an\"      \"average\" \"guy\"     \"that\"   \n",
       "[ ... and 108 more ]\n",
       "-tokens_lemmatized- saved  (10.24 secs)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert `tokens_as_df` to quanteda `tokens` object\n",
    "# 1) we use the lemmatized tokens, because the lookup table is also lemmatized \n",
    "# 2) tokens are case-sensitive\n",
    "tokens_as_qeda = tokens_as_df %>%\n",
    "    as.tokens(use_lemma=T)\n",
    "\n",
    "tokens_as_qeda[1]\n",
    "\n",
    "sv(tokens_as_qeda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of tokens of each doc\n",
    "ntoken_corpus = ntoken(tokens_as_qeda)\n",
    "ntoken_corpus = data.table(pid=names(ntoken_corpus), ntoken=ntoken_corpus)\n",
    "ntoken_corpus[1]\n",
    "sv(ntoken_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_as_qeda (47.5 MB) already loaded, will NOT load again! (0 secs) (2021-03-07 5:55 PM)\n",
      "\"cs_dfm_first200\" saved as \"cs_dfm_first200.rds\" (43.1 MB) (7.55 secs, 2021-03-07 17:56:10)\n"
     ]
    }
   ],
   "source": [
    "# Convert tokens to dfm\n",
    "ld(tokens_as_qeda, force=T)\n",
    "\n",
    "tokens_to_dfm <- function(tokens_as_qeda, startpos=1, endpos=-1) {\n",
    "    # select tokens\n",
    "    tokens = tokens_select(tokens_as_qeda, startpos=startpos, endpos=endpos)\n",
    "    \n",
    "    # create ngram\n",
    "    tokens_ngram = tokens %>%\n",
    "        tokens_ngrams(n=1:2, concatenator = \" \")\n",
    "    \n",
    "    # create dfm\n",
    "    cs_dfm = tokens_ngram %>% dfm(tolower=T, stem=F)\n",
    "}\n",
    "\n",
    "cs_dfm = tokens_to_dfm(tokens_as_qeda)\n",
    "cs_dfm_first200 = tokens_to_dfm(tokens_as_qeda, endpos=200)\n",
    "\n",
    "# sv(cs_dfm)\n",
    "sv(cs_dfm_first200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute B-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"df\" saved as \"nltk_stopwords.feather\" (2.5 KB) (<1s)\n"
     ]
    }
   ],
   "source": [
    "# get stopwords from nltk (Python code)\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "df = pd.DataFrame({'word':list(stopwords)})\n",
    "sv('df', svname='nltk_stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"nltk_stopwords.feather\" (2.5 KB) loaded (0 secs) (2021-03-07 6:00 PM)\n",
      "\"bscore_nostopwords\" saved as \"bscore_nostopwords.rds\" (232.4 KB) (0.04 secs, 2021-03-07 18:00:19)\n",
      "0.310356910447018% words are stopwords"
     ]
    }
   ],
   "source": [
    "# ------------ Create bscore dict ----------------\n",
    "# load stop word list\n",
    "ld(nltk_stopwords, force=T)\n",
    "nltk_stopwords = nltk_stopwords[,word]\n",
    "\n",
    "# read raw bscore\n",
    "bscore_dt = fread('data/concreteness score.csv')[, .(word=str_trim(Word), score=Conc.M)]\n",
    "\n",
    "# create TWO bscore, one has stopwords, one doesn't \n",
    "bscore = bscore_dt$score\n",
    "names(bscore) = bscore_dt$word\n",
    "\n",
    "bscore_nostopwords = bscore[!(names(bscore)%in%nltk_stopwords)]\n",
    "\n",
    "sprintf('%s%% words are stopwords', (1-length(bscore_nostopwords)/length(bscore))*100%>%round(2)) %>% cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ntoken_corpus.rds\" (282.9 KB) loaded (0.02 secs) (2021-03-08 2:28 AM)\n",
      "cs_dfm (116.8 MB) already loaded, will NOT load again! (0 secs) (2021-03-08 2:28 AM)\n",
      "cs_dfm_first200 (43.1 MB) already loaded, will NOT load again! (0 secs) (2021-03-08 2:28 AM)\n",
      "bscore_nostopwords (232.4 KB) already loaded, will NOT load again! (0 secs) (2021-03-08 2:28 AM)\n"
     ]
    }
   ],
   "source": [
    "# ------------ Create bscore from dtm ----------------\n",
    "\n",
    "ld(ntoken_corpus, force=T)\n",
    "ld(cs_dfm)\n",
    "ld(cs_dfm_first200)\n",
    "ld(bscore_nostopwords)\n",
    "\n",
    "\n",
    "dfm_to_bscore <- function(cs_dfm, bscore_dict, type_name='') {\n",
    "    ntoken_name = str_c('ntoken_bscore', type_name)\n",
    "    bscore_name = str_c('bscore', type_name)\n",
    "    \n",
    "    output_name = c('pid', bscore_name)\n",
    "    \n",
    "    dfm_bscore = dfm_match(cs_dfm, names(bscore_dict))\n",
    "    ntoken_bscore = ntoken(dfm_bscore)\n",
    "    ntoken_bscore_dt = data.table(pid=names(ntoken_bscore))\n",
    "    ntoken_bscore_dt[, (ntoken_name) := ntoken_bscore]\n",
    "    \n",
    "    \n",
    "    dfm_bscore_weighted = dfm_weight(dfm_bscore, weights=bscore_dict)\n",
    "    dfm_bscore_weighted = convert(dfm_bscore_weighted, 'data.frame',\n",
    "                                  docid_field='pid'\n",
    "                                 ) %>% as.data.table()\n",
    "    \n",
    "    bscore_by_pid = dfm_bscore_weighted[, (bscore_name) := rowSums(.SD),\n",
    "                                        .SDcols=is.numeric\n",
    "        ][, ..output_name]\n",
    "    \n",
    "    bscore = bscore_by_pid[ntoken_bscore_dt, on=.(pid)]\n",
    "}\n",
    "\n",
    "bscore_bypid = dfm_to_bscore(cs_dfm, bscore)\n",
    "bscore_bypid_nostopwords = dfm_to_bscore(cs_dfm, bscore_nostopwords, \n",
    "                                         type_name='_nostopwords')\n",
    "bscore_bypid_firstn = dfm_to_bscore(cs_dfm_first200, bscore,\n",
    "                                    type_name='_first200')\n",
    "bscore_bypid_firstn_nostopwords = dfm_to_bscore(cs_dfm_first200,\n",
    "                                                bscore_nostopwords,\n",
    "                                                type_name='_first200_nostopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"bscore_bypid\" saved as \"bscore_bypid.feather\" (1.7 MB) (0.01 secs, 2021-03-08 02:28:57)\n"
     ]
    }
   ],
   "source": [
    "bscore_bypid = bscore_bypid[bscore_bypid_nostopwords, on=.(pid)\n",
    "    ][bscore_bypid_firstn, on=.(pid)\n",
    "    ][bscore_bypid_firstn_nostopwords, on=.(pid)\n",
    "    ][ntoken_corpus, on=.(pid)]\n",
    "\n",
    "sv(bscore_bypid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'pid'</li><li>'bscore'</li><li>'ntoken_bscore'</li><li>'bscore_nostopwords'</li><li>'ntoken_bscore_nostopwords'</li><li>'bscore_first200'</li><li>'ntoken_bscore_first200'</li><li>'bscore_first200_nostopwords'</li><li>'ntoken_bscore_first200_nostopwords'</li><li>'ntoken'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'pid'\n",
       "\\item 'bscore'\n",
       "\\item 'ntoken\\_bscore'\n",
       "\\item 'bscore\\_nostopwords'\n",
       "\\item 'ntoken\\_bscore\\_nostopwords'\n",
       "\\item 'bscore\\_first200'\n",
       "\\item 'ntoken\\_bscore\\_first200'\n",
       "\\item 'bscore\\_first200\\_nostopwords'\n",
       "\\item 'ntoken\\_bscore\\_first200\\_nostopwords'\n",
       "\\item 'ntoken'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'pid'\n",
       "2. 'bscore'\n",
       "3. 'ntoken_bscore'\n",
       "4. 'bscore_nostopwords'\n",
       "5. 'ntoken_bscore_nostopwords'\n",
       "6. 'bscore_first200'\n",
       "7. 'ntoken_bscore_first200'\n",
       "8. 'bscore_first200_nostopwords'\n",
       "9. 'ntoken_bscore_first200_nostopwords'\n",
       "10. 'ntoken'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"pid\"                                \"bscore\"                            \n",
       " [3] \"ntoken_bscore\"                      \"bscore_nostopwords\"                \n",
       " [5] \"ntoken_bscore_nostopwords\"          \"bscore_first200\"                   \n",
       " [7] \"ntoken_bscore_first200\"             \"bscore_first200_nostopwords\"       \n",
       " [9] \"ntoken_bscore_first200_nostopwords\" \"ntoken\"                            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(bscore_bypid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.table: 3 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>term</th><th scope=col>Natural disasters</th><th scope=col>Internet</th><th scope=col>Soft drinks</th><th scope=col>Mobile devices</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>economist estimate</td><td>8.806352e-07</td><td>1.497170e-06</td><td>2.32850e-06</td><td>2.045927e-06</td></tr>\n",
       "\t<tr><td>corporate earn    </td><td>2.641906e-06</td><td>1.497170e-06</td><td>1.16425e-06</td><td>1.022963e-06</td></tr>\n",
       "\t<tr><td>earn rose         </td><td>3.522541e-06</td><td>7.485848e-07</td><td>3.49275e-06</td><td>1.022963e-06</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 3 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " term & Natural disasters & Internet & Soft drinks & Mobile devices\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t economist estimate & 8.806352e-07 & 1.497170e-06 & 2.32850e-06 & 2.045927e-06\\\\\n",
       "\t corporate earn     & 2.641906e-06 & 1.497170e-06 & 1.16425e-06 & 1.022963e-06\\\\\n",
       "\t earn rose          & 3.522541e-06 & 7.485848e-07 & 3.49275e-06 & 1.022963e-06\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 3 × 5\n",
       "\n",
       "| term &lt;chr&gt; | Natural disasters &lt;dbl&gt; | Internet &lt;dbl&gt; | Soft drinks &lt;dbl&gt; | Mobile devices &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| economist estimate | 8.806352e-07 | 1.497170e-06 | 2.32850e-06 | 2.045927e-06 |\n",
       "| corporate earn     | 2.641906e-06 | 1.497170e-06 | 1.16425e-06 | 1.022963e-06 |\n",
       "| earn rose          | 3.522541e-06 | 7.485848e-07 | 3.49275e-06 | 1.022963e-06 |\n",
       "\n"
      ],
      "text/plain": [
       "  term               Natural disasters Internet     Soft drinks Mobile devices\n",
       "1 economist estimate 8.806352e-07      1.497170e-06 2.32850e-06 2.045927e-06  \n",
       "2 corporate earn     2.641906e-06      1.497170e-06 1.16425e-06 1.022963e-06  \n",
       "3 earn rose          3.522541e-06      7.485848e-07 3.49275e-06 1.022963e-06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.table: 3 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>term</th><th scope=col>Natural disasters</th><th scope=col>Internet</th><th scope=col>Soft drinks</th><th scope=col>Mobile devices</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>economist estimate</td><td>0.2205428</td><td>0.37494525</td><td>0.58314039</td><td>0.51237388</td></tr>\n",
       "\t<tr><td>corporate earn    </td><td>0.1200810</td><td>0.06804997</td><td>0.05291797</td><td>0.04649615</td></tr>\n",
       "\t<tr><td>earn rose         </td><td>0.1282354</td><td>0.02725166</td><td>0.12715091</td><td>0.03724021</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 3 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " term & Natural disasters & Internet & Soft drinks & Mobile devices\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t economist estimate & 0.2205428 & 0.37494525 & 0.58314039 & 0.51237388\\\\\n",
       "\t corporate earn     & 0.1200810 & 0.06804997 & 0.05291797 & 0.04649615\\\\\n",
       "\t earn rose          & 0.1282354 & 0.02725166 & 0.12715091 & 0.03724021\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 3 × 5\n",
       "\n",
       "| term &lt;chr&gt; | Natural disasters &lt;dbl&gt; | Internet &lt;dbl&gt; | Soft drinks &lt;dbl&gt; | Mobile devices &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| economist estimate | 0.2205428 | 0.37494525 | 0.58314039 | 0.51237388 |\n",
       "| corporate earn     | 0.1200810 | 0.06804997 | 0.05291797 | 0.04649615 |\n",
       "| earn rose          | 0.1282354 | 0.02725166 | 0.12715091 | 0.03724021 |\n",
       "\n"
      ],
      "text/plain": [
       "  term               Natural disasters Internet   Soft drinks Mobile devices\n",
       "1 economist estimate 0.2205428         0.37494525 0.58314039  0.51237388    \n",
       "2 corporate earn     0.1200810         0.06804997 0.05291797  0.04649615    \n",
       "3 earn rose          0.1282354         0.02725166 0.12715091  0.03724021    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_weight_by_topic = fread('data/Structure of News/Word_Weights_By_Topic_Phi.csv')\n",
    "scaled_word_weight_by_topic = fread('data/Structure of News/Scaled_Word_Weights_By_Topic_Phi_tilde.csv')\n",
    "\n",
    "word_weight_by_topic[1:3, 1:5]\n",
    "scaled_word_weight_by_topic[1:3, 1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:1:14: unexpected input\n1: x = double(3)\n                 ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:1:14: unexpected input\n1: x = double(3)\n                 ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "x = double(3)\n",
    "y = 3+x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R-4.0.3",
   "language": "R",
   "name": "ir403"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
